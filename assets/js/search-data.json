{
  
    
        "post0": {
            "title": "Title",
            "content": "import geopandas as gpd import hvplot import hvplot.pandas import numpy as np import pandas as pd import pandas_profiling import pandas_bokeh . dt_dict = { &quot;general_info&quot; : {&quot;path&quot; :&quot;./PARSED DATA/general.xlsx&quot;}, &quot;statistics_1&quot; : {&quot;path&quot; :&quot;./PARSED DATA/statistics_1.xlsx&quot;}, &quot;statistics_2&quot; : {&quot;path&quot; :&quot;./PARSED DATA/statistics_2.xlsx&quot;}, &quot;sro_membership&quot;: {&quot;path&quot; :&quot;./PARSED DATA/sro.xlsx&quot;}, &quot;penalties&quot;: {&quot;path&quot; :&quot;./PARSED DATA/discipline.xlsx&quot;}, } . for data_name, data_name_dict in dt_dict.items(): data_path = data_name_dict.get(&quot;path&quot;) data_raw = pd.read_excel(data_path) data_name_dict[&quot;data_raw&quot;] = data_raw display(data_raw.head(3)) display(data_raw.info()) . ID name attestat reg_number date_added date_sro email reg_number_sro . 0 826933 | Ёжиков Роман Дмитриевич | номер: 13-11-56_x000D_ n   дата выдачи: 07.... | 9624.0 | 03.03.2011 | 30.06.2016 | ezikoff@mail.ru | NaN | . 1 816193 | Ёжикова Анастасия Игоревна | номер: 23-15-1421_x000D_ n   дата выдачи: 1... | 34341.0 | 01.07.2015 | 26.11.2016 | NaN | NaN | . 2 817155 | Ёлчин Евгений Владиславович | номер: 50-11-720_x000D_ n   дата выдачи: 27... | 16912.0 | 06.10.2011 | 28.06.2016 | yolchin@mail.ru | NaN | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 40047 entries, 0 to 40046 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 ID 40047 non-null int64 1 name 39907 non-null object 2 attestat 39843 non-null object 3 reg_number 39907 non-null float64 4 date_added 31652 non-null object 5 date_sro 19166 non-null object 6 email 38261 non-null object 7 reg_number_sro 5913 non-null object dtypes: float64(1), int64(1), object(6) memory usage: 2.4+ MB . None . ID year period total_decisions rejections_27fz decisions_mistakes decisions_suspensions . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 85900 entries, 0 to 85899 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 ID 85900 non-null int64 1 year 85900 non-null int64 2 period 85900 non-null int64 3 total_decisions 85900 non-null int64 4 rejections_27fz 85900 non-null int64 5 decisions_mistakes 85900 non-null int64 6 decisions_suspensions 85900 non-null int64 dtypes: int64(7) memory usage: 4.6 MB . None . ID year period total_decisions rejections_27fz decisions_mistakes decisions_suspensions . 0 826933 | 2014 | 9 | 136 | 1 | 2 | 0 | . 1 826933 | 2014 | 12 | 215 | 2 | 2 | 0 | . 2 826933 | 2015 | 3 | 57 | 2 | 2 | 0 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1048575 entries, 0 to 1048574 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 ID 1048575 non-null int64 1 year 1048575 non-null int64 2 period 1048575 non-null int64 3 total_decisions 1048575 non-null int64 4 rejections_27fz 1048575 non-null int64 5 decisions_mistakes 1048575 non-null int64 6 decisions_suspensions 1048575 non-null int64 dtypes: int64(7) memory usage: 56.0 MB . None . ID sro_name date_sro_incl date_sro_excl sro_excl_reason . 0 826933 | Ассоциация Саморегулируемая организация &quot;Межре... | 30.06.2016 | NaN | NaN | . 1 816193 | Саморегулируемая организация Ассоциация &quot;Неком... | 26.11.2016 | NaN | NaN | . 2 817155 | Ассоциация &quot;Гильдия кадастровых инженеров&quot; | 28.06.2016 | NaN | NaN | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 37441 entries, 0 to 37440 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 ID 37441 non-null int64 1 sro_name 37441 non-null object 2 date_sro_incl 37246 non-null object 3 date_sro_excl 13322 non-null object 4 sro_excl_reason 13479 non-null object dtypes: int64(1), object(4) memory usage: 1.4+ MB . None . ID Мера ДВ Дата решения о применении меры ДВ Основание применения меры ДВ Дата начала ДВ Дата окончания ДВ . 0 824174 | Замечание | 03.12.2020 | Протокол ДК № 62д/12 | 03.12.2020 | 03.12.2020 | . 1 824174 | Замечание | 10.02.2022 | Протокол Дисциплинарной комиссии Ассоциации СР... | 10.02.2022 | 10.02.2022 | . 2 812881 | предписание устранить нарушение в срок до 11.0... | 12.05.2021 | Протокол заседания Дисциплинарного комитета А ... | 12.05.2021 | 11.06.2021 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 5358 entries, 0 to 5357 Data columns (total 6 columns): # Column Non-Null Count Dtype -- -- 0 ID 5358 non-null int64 1 Мера ДВ 5358 non-null object 2 Дата решения о применении меры ДВ 5358 non-null object 3 Основание применения меры ДВ 5358 non-null object 4 Дата начала ДВ 5143 non-null object 5 Дата окончания ДВ 4422 non-null object dtypes: int64(1), object(5) memory usage: 251.3+ KB . None . Необходимые шаги предобработки данных: . Таблица: Общая информация: . Сплит данных аттестата: att_number, att_date | Сплит ФИО: first_name, last_name , middle_name | reg_number: float -&gt; int | Коррекция типа данных для колонок с датами | Переименование колонок по словарю | . Таблица: Членство в СРО . Коррекция типа данных для колонок с датами | Переименование колонок по словарю | . Таблица: Диспицлинарные взыскания . Коррекция типа данных для колонок с датами | Переименование колонок по словарю | Перевод в нижний регистр тип взыскания | . Таблица: Статистика: . Объединение 2х файлов статистики деятельности | Создание колонки statistics_period из year + period (квартал) в формате дат pandas | Переименование колонок по словарю | . Определим словарь для единообразного переименования колонок, а также функции для очистки даннных в разных датасетах . rename_columns_dict = { # Все таблицы &quot;ID&quot;:&quot;id&quot;, # Таблица дисциплинарных взысканий &quot;Мера ДВ&quot;: &quot;penalty_type&quot;, &quot;Дата решения о применении меры ДВ&quot;: &quot;penalty_decision_date&quot;, &quot;Основание применения меры ДВ&quot;: &quot;penalty_decision_reason&quot;, &quot;Дата начала ДВ&quot;: &quot;penalty_start_date&quot;, &quot;Дата окончания ДВ&quot;: &quot;penalty_end_date&quot;, # Таблица членства в СРО &quot;date_sro_incl&quot; : &quot;sro_inclusion_date&quot;, &quot;date_sro_excl&quot; : &quot;sro_exclusion_date&quot;, &quot;sro_excl_reason&quot;: &quot;sro_exclusion_reason&quot;, # Таблица общей информации &quot;date_added&quot; : &quot;added_date&quot;, &quot;date_sro&quot;: &quot;sro_date&quot;, &quot;name&quot;: &quot;full_name&quot;, # Таблица статистики &quot;total_decisions&quot;: &quot;decisions_total&quot;, &quot;rejections_27fz&quot;: &quot;decisions_27fz&quot;, } . def clean_general_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw general info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Разбираем attestat на необходимые поля .assign(att_number = lambda x: x.attestat.str.split(&quot;_&quot;).str[0])#.str.split(&quot; &quot;).str[1]) .assign(att_number = lambda x: x.att_number.str.split(&quot; &quot;).str[1]) .assign(att_date = lambda x: x.attestat.str.split(&quot;дата выдачи: &quot;).str[1]) .drop(&quot;attestat&quot;, axis=1) # Разбираем ФИО. При такой реализации могут быть ошибки в нестандартных именах .assign(first_name = lambda x: x.name.str.split(&quot; &quot;).str[1]) .assign(last_name = lambda x: x.name.str.split(&quot; &quot;).str[0]) .assign(middle_name = lambda x: x.name.str.split(&quot; &quot;).str[-1]) # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат данных .assign(reg_number = lambda x: x.reg_number.astype(&quot;Int64&quot;)) # Меняем формат дат .assign(added_date = lambda x: pd.to_datetime(x.added_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) .assign(sro_date = lambda x: pd.to_datetime(x.sro_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) .assign(att_date = lambda x: pd.to_datetime(x.att_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) ) return df_clean def clean_sro_membership_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw SRO membership info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат дат .assign(sro_inclusion_date = lambda x: pd.to_datetime(x.sro_inclusion_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(sro_exclusion_date = lambda x: pd.to_datetime(x.sro_exclusion_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) ) return df_clean def clean_penalties_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw penalties info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат дат .assign(penalty_decision_date = lambda x: pd.to_datetime(x.penalty_decision_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(penalty_start_date = lambda x: pd.to_datetime(x.penalty_start_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(penalty_end_date = lambda x: pd.to_datetime(x.penalty_end_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) # Переводим в нижний регистр тип взыскания .assign(penalty_type = lambda x: x.penalty_type.str.lower()) ) return df_clean def clean_statistics_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw statistics info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Создадим колонку с периодами деятельности .assign(statistics_period = lambda x: x.period.astype(str)+ &quot;-&quot;+ x.year.astype(str)) .assign(statistics_period = lambda x: (pd.to_datetime(x.statistics_period, format=&quot;%m-%Y&quot;,errors=&quot;coerce&quot;) + pd.offsets.MonthEnd(0)).dt.date) .assign(quarter = lambda x: (x.period/3).astype(&quot;int64&quot;)) ) return df_clean . dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] = clean_general_df(dt_dict[&quot;general_info&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics_1&quot;][&quot;data_clean&quot;] = clean_statistics_df(dt_dict[&quot;statistics_1&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics_2&quot;][&quot;data_clean&quot;] = clean_statistics_df(dt_dict[&quot;statistics_2&quot;][&quot;data_raw&quot;]) dt_dict[&quot;sro_membership&quot;][&quot;data_clean&quot;] = clean_sro_membership_df(dt_dict[&quot;sro_membership&quot;][&quot;data_raw&quot;]) dt_dict[&quot;penalties&quot;][&quot;data_clean&quot;] = clean_penalties_df(dt_dict[&quot;penalties&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics&quot;] = {&quot;data_clean&quot;: pd.concat([dt_dict[&quot;statistics_1&quot;][&quot;data_clean&quot;], dt_dict[&quot;statistics_2&quot;][&quot;data_clean&quot;], ])} for k, v in dt_dict.items(): display(v.get(&quot;data_clean&quot;).head(3)) . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name . 0 826933 | Ёжиков Роман Дмитриевич | 9624 | 2011-03-03 | 2016-06-30 | ezikoff@mail.ru | NaN | 13-11-56 | 2011-02-07 | Роман | Ёжиков | Дмитриевич | . 1 816193 | Ёжикова Анастасия Игоревна | 34341 | 2015-07-01 | 2016-11-26 | NaN | NaN | 23-15-1421 | 2015-06-17 | Анастасия | Ёжикова | Игоревна | . 2 817155 | Ёлчин Евгений Владиславович | 16912 | 2011-10-06 | 2016-06-28 | yolchin@mail.ru | NaN | 50-11-720 | 2011-09-27 | Евгений | Ёлчин | Владиславович | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 826933 | 2014 | 9 | 136 | 1 | 2 | 0 | 2014-09-30 | 3 | . 1 826933 | 2014 | 12 | 215 | 2 | 2 | 0 | 2014-12-31 | 4 | . 2 826933 | 2015 | 3 | 57 | 2 | 2 | 0 | 2015-03-31 | 1 | . id sro_name sro_inclusion_date sro_exclusion_date sro_exclusion_reason . 0 826933 | Ассоциация Саморегулируемая организация &quot;Межре... | 2016-06-30 | NaT | NaN | . 1 816193 | Саморегулируемая организация Ассоциация &quot;Неком... | 2016-11-26 | NaT | NaN | . 2 817155 | Ассоциация &quot;Гильдия кадастровых инженеров&quot; | 2016-06-28 | NaT | NaN | . id penalty_type penalty_decision_date penalty_decision_reason penalty_start_date penalty_end_date . 0 824174 | замечание | 2020-12-03 | Протокол ДК № 62д/12 | 2020-12-03 | 2020-12-03 | . 1 824174 | замечание | 2022-02-10 | Протокол Дисциплинарной комиссии Ассоциации СР... | 2022-02-10 | 2022-02-10 | . 2 812881 | предписание устранить нарушение в срок до 11.0... | 2021-05-12 | Протокол заседания Дисциплинарного комитета А ... | 2021-05-12 | 2021-06-11 | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | . &#1040;&#1085;&#1072;&#1083;&#1080;&#1079; . Посмотрим внимательнее на признак &quot;Номер аттестата&quot; att_number и попробуем понять, значат ли что-то цифры его составляющие. Больше всего мы бы хотели вытащить информацию о регионах выдачи аттестатов и, может быть, одна из цифр кодирует регион. Если это так, то регионов должно быть около 85, а максимальное количество инженеров ожидается в 50-м, 77-м, 78-м регионах . _att_number_df = dt_dict[&quot;general_info&quot;].get(&quot;data_clean&quot;)[&quot;att_number&quot;] _att_number_df = _att_number_df.str.split(&quot;-&quot;, expand=True) _att_number_df = _att_number_df.dropna() _att_number_df = _att_number_df.astype(&quot;int64&quot;, errors=&quot;raise&quot;) _att_number_df = _att_number_df.rename(columns={0: &quot;smt_0&quot;, 1: &quot;smt_1&quot;, 2: &quot;smt_2&quot;}) display(_att_number_df[&quot;smt_0&quot;].nunique()) display(_att_number_df[&quot;smt_1&quot;].nunique()) display(_att_number_df[&quot;smt_2&quot;].nunique()) . 83 . 7 . 1577 . Отлично! Гипотеза пока не опровержена. . Количество уникальных объектов первой части атт.номера близко кол-ву субъектов рф | Вторая часть номера тоже представляет интерес: уникальных значений всего 7. Но что это может быть - пока не понятно | . Проверим количество аттестатов по предполагаемому признаку региона . pd.set_option(&quot;plotting.backend&quot;, &quot;hvplot&quot;) # Посчитаем количество _df = _att_number_df[&quot;smt_0&quot;].value_counts().sort_values(ascending=True) # Выберем и пометим первые и последние 10 значений n_to_show = 10 _df = ( pd.DataFrame(_df.iloc[np.r_[0:n_to_show, -n_to_show:0]]) .reset_index() .rename(columns={&quot;index&quot;: &quot;region&quot;, &quot;smt_0&quot;: &quot;attestats_count&quot;}) ) _df[&quot;rating&quot;] = f&quot;Top-{n_to_show}&quot; _df.loc[: n_to_show - 1, &quot;rating&quot;] = f&quot;Bottom-{n_to_show}&quot; # Выведем график _df.hvplot.barh( x=&quot;region&quot;, y=&quot;attestats_count&quot;, color=&quot;rating&quot;, cmap=[&quot;pink&quot;, &quot;blue&quot;], title=&quot;Количество аттестатов в top/bottom-10 регионах&quot;, legend=&quot;right&quot;, ) . Гипотеза о том, что в номере аттестата закодирован регион выдачи - подтвердилась. . Наибольшее количество аттестатов выдано в Москве | Удивительно, но на 2-м и 3-м месте, обгоняя Московскую Область, находятся Краснодарский край и Республика Башкортостан | . Дополним очищенный датасет с основной информацией по кадастровым инженерам данными о регионе. Для удобства дальнейшей интерпретации численных обозначений регионов скачаем &quot;подсказку&quot; . region_naming = pd.read_csv( &quot;https://raw.githubusercontent.com/hflabs/region/master/region.csv&quot;, dtype=object, ) # Достаем необходимые поля из таблицы регионов geoname_df = region_naming.loc[:, [&quot;kladr_id&quot;, &quot;geoname_name&quot;, &quot;iso_code&quot;]] geoname_df[&quot;code&quot;] = geoname_df[&quot;kladr_id&quot;].str[0:2] #geoname_df[&quot;iso_code&quot;] = geoname_df[&quot;iso_code&quot;].str.replace(&quot;-&quot;, &quot;.&quot;) display(geoname_df.head(3)) # Смерджим данные в датафрейм с основной информацией general_info_clean = dt_dict[&quot;general_info&quot;].get(&quot;data_clean&quot;).copy() general_info_clean[&quot;att_region&quot;] = ( general_info_clean[&quot;att_number&quot;].str.split(&quot;-&quot;, expand=False).str[0] ) general_info_clean = general_info_clean.merge( geoname_df[[&quot;geoname_name&quot;, &quot;code&quot;, &quot;iso_code&quot;]], how=&#39;left&#39;, left_on=&quot;att_region&quot;, right_on=&quot;code&quot;, ).drop(&quot;code&quot;, axis=1) # Посмотрим на результат и сохраним в словаре с данными display(general_info_clean.head(3)) dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] = general_info_clean . kladr_id geoname_name iso_code code . 0 0100000000000 | Adygeya Republic | RU-AD | 01 | . 1 0200000000000 | Bashkortostan Republic | RU-BA | 02 | . 2 0300000000000 | Buryatiya Republic | RU-BU | 03 | . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name att_region geoname_name iso_code . 0 826933 | Ёжиков Роман Дмитриевич | 9624 | 2011-03-03 | 2016-06-30 | ezikoff@mail.ru | NaN | 13-11-56 | 2011-02-07 | Роман | Ёжиков | Дмитриевич | 13 | Mordoviya Republic | RU-MO | . 1 816193 | Ёжикова Анастасия Игоревна | 34341 | 2015-07-01 | 2016-11-26 | NaN | NaN | 23-15-1421 | 2015-06-17 | Анастасия | Ёжикова | Игоревна | 23 | Krasnodarskiy | RU-KDA | . 2 817155 | Ёлчин Евгений Владиславович | 16912 | 2011-10-06 | 2016-06-28 | yolchin@mail.ru | NaN | 50-11-720 | 2011-09-27 | Евгений | Ёлчин | Владиславович | 50 | Moscow Oblast | RU-MOS | . region_naming.head() . name type name_with_type federal_district kladr_id fias_id okato oktmo tax_office postal_code iso_code timezone geoname_code geoname_id geoname_name . 0 Адыгея | Респ | Респ Адыгея | Южный | 0100000000000 | d8327a56-80de-4df2-815c-4f6ab1224c50 | 79000000000 | 79000000 | 0100 | 385000 | RU-AD | UTC+3 | RU.01 | 584222 | Adygeya Republic | . 1 Башкортостан | Респ | Респ Башкортостан | Приволжский | 0200000000000 | 6f2cbfd8-692a-4ee4-9b16-067210bde3fc | 80000000000 | 80000000 | 0200 | 452000 | RU-BA | UTC+5 | RU.08 | 578853 | Bashkortostan Republic | . 2 Бурятия | Респ | Респ Бурятия | Дальневосточный | 0300000000000 | a84ebed3-153d-4ba9-8532-8bdf879e1f5a | 81000000000 | 81000000 | 0300 | 671000 | RU-BU | UTC+8 | RU.11 | 2050915 | Buryatiya Republic | . 3 Алтай | Респ | Респ Алтай | Сибирский | 0400000000000 | 5c48611f-5de6-4771-9695-7e36a4e7529d | 84000000000 | 84000000 | 0400 | 649000 | RU-AL | UTC+7 | RU.03 | 1506272 | Altai | . 4 Дагестан | Респ | Респ Дагестан | Северо-Кавказский | 0500000000000 | 0bb7fa19-736d-49cf-ad0e-9774c4dae09b | 82000000000 | 82000000 | 0500 | 368000 | RU-DA | UTC+3 | RU.17 | 567293 | Dagestan | . _df = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] _df.loc[(_df[&quot;last_name&quot;]==&quot;Иванова&quot;) &amp; (_df[&quot;first_name&quot;]==&quot;Екатерина&quot;) ] . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name att_region geoname_name iso_code . 12763 839234 | Иванова Екатерина Алексеевна | 23076 | 2012-11-21 | 2016-06-02 | NaN | NaN | 69-12-528 | 2012-11-07 | Екатерина | Иванова | Алексеевна | 69 | Tver Oblast | RU-TVE | . 12807 833816 | Иванова Екатерина Андреевна | 34311 | 2015-06-26 | 2016-11-17 | katis05@mail.ru | 1021 | 77-15-115 | 2015-05-29 | Екатерина | Иванова | Андреевна | 77 | Moscow | RU-MOW | . 12818 813232 | Иванова Екатерина Валентиновна | 16218 | 2011-08-30 | NaT | geo.centr@mail.ru | 32 | 50-11-689 | 2011-08-23 | Екатерина | Иванова | Валентиновна | 50 | Moscow Oblast | RU-MOS | . 12883 839340 | Иванова Екатерина Николаевна | 1312 | 2010-12-17 | NaT | katerina_perm_23@mail.ru | 260 | 59-10-91 | 2010-12-09 | Екатерина | Иванова | Николаевна | 59 | Perm | RU-PER | . Проанализируем статистику деятельности кад.инженеров во времени: . Посчитаем суммарное количество отказов по всем причинам | Посчитаем долю отказов | . (!) Так как обработка документов Росреестром растянуто во времени, могут быть кварталы, когда количество полученных в периоде отказов (по сути, по поданным ранее документам) превышает количество поданных в периоде документов . statistics_df = dt_dict[&quot;statistics&quot;][&quot;data_clean&quot;] cols_to_sum = [&quot;decisions_27fz&quot;, &quot;decisions_mistakes&quot;, &quot;decisions_suspensions&quot;] statistics_df[&quot;rejections_total&quot;] = statistics_df[cols_to_sum].sum(axis=1) statistics_df[&quot;acceptions_total&quot;] = statistics_df[&quot;decisions_total&quot;] - statistics_df[&quot;rejections_total&quot;] statistics_df[&quot;rejections_share&quot;] = ( statistics_df[&quot;rejections_total&quot;] / statistics_df[&quot;decisions_total&quot;] ) statistics_df[&quot;acceptions_share&quot;] = ( statistics_df[&quot;acceptions_total&quot;] / statistics_df[&quot;decisions_total&quot;] ) display(statistics_df.head(3)) . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter rejections_total acceptions_total rejections_share acceptions_share . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | 0 | 49 | 0.000000 | 1.000000 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | 8 | 127 | 0.059259 | 0.940741 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | 12 | 165 | 0.067797 | 0.932203 | . Посмотрим на агрегированную статистику отказов во времени. Так как отказы Росрееста получаются с временным лагом, возможна ситуация, когда доля отказов &gt; 1. . _df = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() (_df[[&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;statistics_period&quot;]] .groupby(&quot;statistics_period&quot;) .sum() .hvplot.bar( stacked=True, x=&quot;statistics_period&quot;, yformatter=&#39;%.0e&#39;, width = 1000, title = &quot;Поквартальное (накопленное за год) количество одобренных и отвегнутых документов&quot;, ylabel = &quot;Документов&quot;, xlabel = &quot;&quot;, rot=90)) . Мы видим, что с начала 2019 года явно поменялась структура и/или подход к проверке документов: при сохранении общей динамики и сезонности, количество отказов возрасло многократно. В вики ведомства ничего примечательного относительно 2018-2019 годов не написано, да и на TAdvisor тоже ничего примечательного в данные периоды. . Посмотрим на динамику доли отказов . _df2 = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() _df2 = _df2[[&quot;decisions_total&quot;, &quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;statistics_period&quot;]].groupby(&quot;statistics_period&quot;).agg(&quot;sum&quot;) # Пересчитаем доли на агрегатах _df2[&quot;rejections_share&quot;] = ( _df2[&quot;rejections_total&quot;] / _df2[&quot;decisions_total&quot;] ) _df2[&quot;acceptions_share&quot;] = ( _df2[&quot;acceptions_total&quot;] / _df2[&quot;decisions_total&quot;] ) _df2.hvplot.bar( stacked=True, x=&quot;statistics_period&quot;, y=[&quot;acceptions_share&quot;, &quot;rejections_share&quot;,], width = 1000, title = &quot;Поквартальная доля одобренных и отвегнутых документов&quot;, ylabel = &quot;Доля документов&quot;, xlabel = &quot;&quot;, rot=90) . Мы видим, что начиная с 2019 года, за исключением одного квартала, доля отклоненных документов уверенно превышает 10%. А ведь эти документы подает не кто-то прохожий с улицы, а аттестованные &quot;профессионалы&quot; кадастровой деятельности. Если представить, что с таким уровнем сервиса (где доля отказов &gt;10%) работает коммерческая компания - то незавидной, недолгой и печальной кажется ее судьба, но монопольное положение Росреестра и его кадастровых инженеров это позволяет. &quot;И пусть весь мир подождет&quot; (с) какая-то реклама . _df[&quot;statistics_period&quot;].head() . 0 2020-03-31 1 2020-06-30 2 2020-09-30 3 2020-12-31 4 2021-03-31 Name: statistics_period, dtype: object . import pandas as pd import requests import geopandas as gpd from osm2geojson import json2geojson overpass_url = &quot;http://overpass-api.de/api/interpreter&quot; overpass_query = &quot;&quot;&quot; [out:json]; rel[admin_level=4] [type=boundary] [boundary=administrative] [&quot;ISO3166-2&quot;~&quot;^RU&quot;]; out geom; &quot;&quot;&quot; response = requests.get(overpass_url, params={&#39;data&#39;: overpass_query}) response.raise_for_status() data = response.json() geojson_data = json2geojson(data) gdf_osm = gpd.GeoDataFrame.from_features(geojson_data) # Конвертируем словари тэгов в колонки df_tags = gdf_osm[&quot;tags&quot;].apply(pd.Series) # Определим, какие колонки оставить для дальнейшего анализа cols_keep = [] for col in list(df_tags.columns): if &quot;name:&quot; not in col: cols_keep.append(col) cols_keep.extend([&quot;name:en&quot;, &quot;name:ru&quot;]) # Получим финальный геодатафрейм с нужными колонками gdf_full = pd.concat([gdf_osm, df_tags.loc[:,cols_keep]], axis=1) display(gdf_full.head()) . geometry type id tags ISO3166-2 addr:country admin_level border_type boundary cadaster:code ... place source:population alt_name2 old_name gis-lab:status source:url country ref:en name:en name:ru . 0 MULTIPOLYGON (((35.14891 55.95777, 35.14850 55... | relation | 51490 | {&#39;ISO3166-2&#39;: &#39;RU-MOS&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-MOS | RU | 4 | region | administrative | 50 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Moscow Oblast | Московская область | . 1 MULTIPOLYGON (((38.67446 54.25787, 38.66852 54... | relation | 71950 | {&#39;ISO3166-2&#39;: &#39;RU-RYA&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-RYA | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ryazan Oblast | Рязанская область | . 2 MULTIPOLYGON (((37.73038 52.60995, 37.72625 52... | relation | 72169 | {&#39;ISO3166-2&#39;: &#39;RU-LIP&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-LIP | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Lipetsk Oblast | Липецкая область | . 3 MULTIPOLYGON (((39.91569 52.70885, 39.92159 52... | relation | 72180 | {&#39;ISO3166-2&#39;: &#39;RU-TAM&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-TAM | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Tambov Oblast | Тамбовская область | . 4 MULTIPOLYGON (((38.14031 51.63704, 38.14045 51... | relation | 72181 | {&#39;ISO3166-2&#39;: &#39;RU-VOR&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-VOR | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Voronezh Oblast | Воронежская область | . 5 rows × 54 columns . import shapely import warnings from shapely.errors import ShapelyDeprecationWarning warnings.filterwarnings(&quot;ignore&quot;, category=ShapelyDeprecationWarning) pd.set_option(&#39;plotting.backend&#39;, &#39;pandas_bokeh&#39;) gdf_full_mercator = gdf_full.set_crs(&#39;epsg:4326&#39;) output_notebook() gdf_full_mercator.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;], title=&quot;Пустая карта РФ&quot;, xlim=[20, 180], ylim=[40, 80], ) . NameError Traceback (most recent call last) /Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb Cell 31&#39; in &lt;cell line: 9&gt;() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=5&#39;&gt;6&lt;/a&gt; pd.set_option(&#39;plotting.backend&#39;, &#39;pandas_bokeh&#39;) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=7&#39;&gt;8&lt;/a&gt; gdf_full_mercator = gdf_full.set_crs(&#39;epsg:4326&#39;) -&gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=8&#39;&gt;9&lt;/a&gt; output_notebook() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=9&#39;&gt;10&lt;/a&gt; gdf_full_mercator.plot_bokeh( &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=10&#39;&gt;11&lt;/a&gt; figsize = (1000, 600), &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=11&#39;&gt;12&lt;/a&gt; simplify_shapes=20000, (...) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=16&#39;&gt;17&lt;/a&gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=17&#39;&gt;18&lt;/a&gt; ) NameError: name &#39;output_notebook&#39; is not defined . _df = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() _df_general = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] _df = _df.merge(_df_general, how=&quot;left&quot;, on=&quot;id&quot;) _df.head(3) _df3 = (_df[[&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;year&quot;, &quot;att_region&quot;,&quot;iso_code&quot;]] .groupby([&quot;year&quot;, &quot;iso_code&quot;]) .sum()) # Пересчитаем доли на агрегатах _df3[&quot;rejections_share&quot;] = ( _df3[&quot;rejections_total&quot;] / _df3[&quot;decisions_total&quot;] ) _df2[&quot;acceptions_share&quot;] = ( _df3[&quot;acceptions_total&quot;] / _df3[&quot;decisions_total&quot;] ) annual_reg_stat = _df3.reset_index() annual_reg_stat . year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 2014 | RU-AD | 90406 | 88318 | 2088 | 0.023096 | . 1 2014 | RU-AL | 18140 | 17853 | 287 | 0.015821 | . 2 2014 | RU-ALT | 77748 | 76185 | 1563 | 0.020103 | . 3 2014 | RU-AMU | 61431 | 60253 | 1178 | 0.019176 | . 4 2014 | RU-ARK | 45471 | 45277 | 194 | 0.004266 | . ... ... | ... | ... | ... | ... | ... | . 651 2021 | RU-VOR | 136037 | 127645 | 8392 | 0.061689 | . 652 2021 | RU-YAN | 7599 | 7502 | 97 | 0.012765 | . 653 2021 | RU-YAR | 62378 | 47058 | 15320 | 0.245599 | . 654 2021 | RU-YEV | 1232 | 1128 | 104 | 0.084416 | . 655 2021 | RU-ZAB | 26361 | 18298 | 8063 | 0.305869 | . 656 rows × 6 columns . reg_stat_2021 = annual_reg_stat.loc[annual_reg_stat[&quot;year&quot;]==2021,] reg_stat_2021 = reg_stat_2021.replace(&quot;&quot;,np.nan).dropna() #display(reg_stat_2021.head(3)) #display(gdf_full_mercator.head(3)) points_to_map = gdf_full_mercator.merge(reg_stat_2021, how=&quot;left&quot;, left_on=&quot;ISO3166-2&quot;, right_on=&quot;iso_code&quot;) #Replace NaN values to string &#39;No data&#39;. points_to_map.loc[:,[&quot;year&quot;,&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;rejections_share&quot;]].fillna(&#39;No data&#39;, inplace = True) points_to_map.head() . geometry type id tags ISO3166-2 addr:country admin_level border_type boundary cadaster:code ... country ref:en name:en name:ru year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 MULTIPOLYGON (((35.14891 55.95777, 35.14850 55... | relation | 51490 | {&#39;ISO3166-2&#39;: &#39;RU-MOS&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-MOS | RU | 4 | region | administrative | 50 | ... | NaN | NaN | Moscow Oblast | Московская область | 2021.0 | RU-MOS | 154293.0 | 41475.0 | 112818.0 | 0.731193 | . 1 MULTIPOLYGON (((38.67446 54.25787, 38.66852 54... | relation | 71950 | {&#39;ISO3166-2&#39;: &#39;RU-RYA&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-RYA | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Ryazan Oblast | Рязанская область | 2021.0 | RU-RYA | 91092.0 | 55574.0 | 35518.0 | 0.389913 | . 2 MULTIPOLYGON (((37.73038 52.60995, 37.72625 52... | relation | 72169 | {&#39;ISO3166-2&#39;: &#39;RU-LIP&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-LIP | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Lipetsk Oblast | Липецкая область | 2021.0 | RU-LIP | 37730.0 | 35923.0 | 1807.0 | 0.047893 | . 3 MULTIPOLYGON (((39.91569 52.70885, 39.92159 52... | relation | 72180 | {&#39;ISO3166-2&#39;: &#39;RU-TAM&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-TAM | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Tambov Oblast | Тамбовская область | 2021.0 | RU-TAM | 43556.0 | 39205.0 | 4351.0 | 0.099894 | . 4 MULTIPOLYGON (((38.14031 51.63704, 38.14045 51... | relation | 72181 | {&#39;ISO3166-2&#39;: &#39;RU-VOR&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-VOR | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Voronezh Oblast | Воронежская область | 2021.0 | RU-VOR | 136037.0 | 127645.0 | 8392.0 | 0.061689 | . 5 rows × 60 columns . points_to_map.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;, &quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;rejections_share&quot;], dropdown = [&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;], title=&quot;2021&quot;, #colormap_uselog=True, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0.0a&quot;, xlim=[20, 180], ylim=[40, 80], ) . Column(id&nbsp;=&nbsp;&#39;6199&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[Select(id=&#39;6197&#39;, ...), Figure(id=&#39;6126&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) html_plot = points_to_map.plot_bokeh( figsize=(1000, 600), simplify_shapes=20000, hovertool_columns=[ &quot;name:ru&quot;, &quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, ], dropdown=[&quot;rejections_share&quot;], title=&quot;2021&quot;, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0%&quot;, return_html=True, xlim=[20, 180], ylim=[40, 80], ) # Export the HTML string to an external HTML file and show it: with open(&quot;test.html&quot;, &quot;w&quot;) as f: f.write(r&quot;&quot;&quot;&quot;&quot;&quot; + html_plot) . Визуализируем изменение доли отказов по регионам во времени. Ранее мы определили, что отказы &quot;поперли&quot; только с 2019 года. Соответственно статистику отобразим с этого момента. Для этого аггрегируем данные по годам/регионам и подготовим dataframe в wide формате для возможности отображения на географике. . display(annual_reg_stat.head()) statistics_df_wide = annual_reg_stat.pivot(index=&quot;iso_code&quot;, columns=[&quot;year&quot;,]) # Убираем мультииндекс и объединяем название колонок с годами statistics_df_wide.columns = [&#39;_&#39;.join((col[0],str(col[1]))) for col in statistics_df_wide.columns] statistics_df_wide.reset_index(inplace=True) statistics_df_wide.head() . year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 2014 | RU-AD | 90406 | 88318 | 2088 | 0.023096 | . 1 2014 | RU-AL | 18140 | 17853 | 287 | 0.015821 | . 2 2014 | RU-ALT | 77748 | 76185 | 1563 | 0.020103 | . 3 2014 | RU-AMU | 61431 | 60253 | 1178 | 0.019176 | . 4 2014 | RU-ARK | 45471 | 45277 | 194 | 0.004266 | . iso_code decisions_total_2014 decisions_total_2015 decisions_total_2016 decisions_total_2017 decisions_total_2018 decisions_total_2019 decisions_total_2020 decisions_total_2021 acceptions_total_2014 ... rejections_total_2020 rejections_total_2021 rejections_share_2014 rejections_share_2015 rejections_share_2016 rejections_share_2017 rejections_share_2018 rejections_share_2019 rejections_share_2020 rejections_share_2021 . 0 RU-AD | 90406 | 113177 | 118257 | 80315 | 112610 | 101365 | 103318 | 103807 | 88318 | ... | 4630 | 6130 | 0.023096 | 0.015427 | 0.014392 | 0.004968 | 0.005621 | 0.051349 | 0.044813 | 0.059052 | . 1 RU-AL | 18140 | 29376 | 25000 | 18354 | 16829 | 15671 | 17242 | 28678 | 17853 | ... | 3532 | 2165 | 0.015821 | 0.012595 | 0.026600 | 0.002016 | 0.002020 | 0.102801 | 0.204849 | 0.075493 | . 2 RU-ALT | 77748 | 144355 | 121379 | 90999 | 109766 | 108327 | 69803 | 87897 | 76185 | ... | 2299 | 2257 | 0.020103 | 0.010911 | 0.006286 | 0.000835 | 0.001494 | 0.030934 | 0.032936 | 0.025678 | . 3 RU-AMU | 61431 | 80261 | 67780 | 53181 | 52099 | 39958 | 37574 | 45157 | 60253 | ... | 2347 | 3743 | 0.019176 | 0.026065 | 0.033579 | 0.005303 | 0.005240 | 0.076455 | 0.062463 | 0.082889 | . 4 RU-ARK | 45471 | 56499 | 51441 | 50128 | 42273 | 6389 | 14047 | 36597 | 45277 | ... | 3073 | 2699 | 0.004266 | 0.002584 | 0.001575 | 0.001875 | 0.003903 | 0.258256 | 0.218766 | 0.073749 | . 5 rows × 33 columns . statistics_df_wide.fillna(&#39;No data&#39;, inplace = True) # Combine statistics with geodataframe history_to_map = gdf_full_mercator.merge(statistics_df_wide, how=&quot;left&quot;, left_on=&quot;ISO3166-2&quot;, right_on=&quot;iso_code&quot;) #Specify slider columns: slider_columns = [&quot;rejections_share_%d&quot;%i for i in range(2019, 2022)] #Specify slider columns: slider_range = range(2019, 2022) history_to_map.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;]+slider_columns, slider=slider_columns, slider_range=slider_range, slider_name=&quot;Year&quot;, title=&quot;Изменение доли отказов по регионам/годам&quot;, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0%&quot;, xlim=[20, 180], ylim=[40, 80], ) . Column(id&nbsp;=&nbsp;&#39;39722&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[Slider(id=&#39;39720&#39;, ...), Figure(id=&#39;39648&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) В 2020 году лидером по доле отказов была Астраханская область. &quot;Зарезано&quot; 90% поданных документов. В 2021 году в лидеры вырывается Московская область с 73% отказов. . Цифры колоссальные, если учесть сколько труда стоит за каждым из документов: . как минимум, несколько часов работы кадастрового инженера | сходить в МФЦ (в лучшем случае) и подать их | время сотрудников росреестра на формирование отказа | . Речь идет буквально о сотнях тысяч человекочасов не самых дешевых сотрудников ежегодно. В пустоту. Более того, за каждым отказом есть своя история расстройства семьи, неначатого бизнеса, затянутого инвестпроекта. . Система с такой долей отказов - ущербная, не работающая. Я могу лишь строить догадки, что такой уровень отказов выгоден самим кадастровым инженерам и повышает корупционную емкость кадастрового дела. Все при деле, работают. . &#1055;&#1088;&#1086;&#1072;&#1085;&#1072;&#1083;&#1080;&#1079;&#1080;&#1088;&#1091;&#1077;&#1084; &#1088;&#1072;&#1073;&#1086;&#1090;&#1091; &#1080;&#1085;&#1076;&#1080;&#1074;&#1080;&#1076;&#1091;&#1072;&#1083;&#1100;&#1085;&#1099;&#1093; &#1080;&#1085;&#1078;&#1077;&#1085;&#1077;&#1088;&#1086;&#1074; . kadeng_stat = statistics_df.copy() _df_general = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] kadeng_stat = kadeng_stat.merge(_df_general, how=&quot;left&quot;, on=&quot;id&quot;) # Сгруппируем данные по кадастровым инженерам и годам kadeng_stat_agg = (kadeng_stat[[&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;year&quot;,&quot;id&quot;, &quot;att_region&quot;]] .groupby([&quot;att_region&quot;,&quot;id&quot;, &quot;year&quot;]) .sum()) # Пересчитаем доли на агрегатах kadeng_stat_agg[&quot;rejections_share&quot;] = ( kadeng_stat_agg[&quot;rejections_total&quot;] / kadeng_stat_agg[&quot;decisions_total&quot;] ) kadeng_stat_agg[&quot;acceptions_share&quot;] = ( kadeng_stat_agg[&quot;acceptions_total&quot;] / kadeng_stat_agg[&quot;decisions_total&quot;] ) kadeng_stat_agg.replace([np.inf, -np.inf], np.nan, inplace=True) kadeng_stat_agg = kadeng_stat_agg.reset_index(drop=False) . kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].describe() . id year decisions_total acceptions_total rejections_total rejections_share acceptions_share . count 39621.000000 | 39621.0 | 39621.000000 | 39621.00000 | 39621.000000 | 19987.000000 | 19987.000000 | . mean 824274.963580 | 2021.0 | 148.937760 | 129.19843 | 19.739330 | 0.247760 | 0.752240 | . std 11646.219417 | 0.0 | 436.343914 | 417.77568 | 65.527005 | 0.721857 | 0.721857 | . min 804223.000000 | 2021.0 | 0.000000 | -618.00000 | 0.000000 | 0.000000 | -36.666667 | . 25% 814220.000000 | 2021.0 | 0.000000 | 0.00000 | 0.000000 | 0.000000 | 0.769231 | . 50% 824232.000000 | 2021.0 | 1.000000 | 0.00000 | 0.000000 | 0.065068 | 0.934932 | . 75% 834221.000000 | 2021.0 | 155.000000 | 121.00000 | 10.000000 | 0.230769 | 1.000000 | . max 850716.000000 | 2021.0 | 28630.000000 | 28511.00000 | 3323.000000 | 37.666667 | 1.000000 | . decisions_total_hist = kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].plot_bokeh( kind=&quot;hist&quot;, bins = 100, y=[&quot;decisions_total&quot;], xlim=(0, 3000), vertical_xlabel=True, show_average = True, title = &quot;РФ_2021: Количество поданных документов&quot;, show_figure=False, ) rejections_share_hist = kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].dropna().plot_bokeh( kind=&quot;hist&quot;, bins=np.arange(0, 3.5, 0.1), y=&quot;rejections_share&quot;, xlim=(0, 2), vertical_xlabel=True, show_average = True, title = &quot;РФ_2021: Доля отказов&quot;, show_figure=False, ) pandas_bokeh.plot_grid([[decisions_total_hist, rejections_share_hist]], width=400, height=300) . Column(id&nbsp;=&nbsp;&#39;2021&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[ToolbarBox(id=&#39;2020&#39;, ...), GridBox(id=&#39;2018&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) В 2021 году средняя доля отказов в группировке по кадастровым инженерам составляет почти 25% - вдвое больше, чем доля отказов по суммарному количеству документов. Гипотеза: есть небольшое количество &quot;супер-успешных&quot; кадастровых инженеров, с большим количеством поданных документов, которые &quot;проходят&quot; на отлично и которые вытягивают среднюю статистику . Посмотрим аналогичную статистику по Московской области . def plot_hist_by_region(year, region_num, kadeng_stat_agg): if isinstance(region_num, int): region_num=str(region_num) _decisions_total_hist = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;] == year) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))].plot_bokeh( kind=&quot;hist&quot;, bins = 30, y=[&quot;decisions_total&quot;], #xlim=(0, 3000), vertical_xlabel=True, show_average = True, title = f&quot;{region_num}_{year}: Количество поданных документов&quot;, #&quot;РФ 2021: Количество поданных документов&quot;, show_figure=False, ) _rejections_share_hist = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;] == year) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))].dropna().plot_bokeh( kind=&quot;hist&quot;, #bins=np.arange(0, 2.5, 0.1), bins = 30, y=[&quot;rejections_share&quot;], #xlim=(0, 2.5), vertical_xlabel=True, show_average = True, title = f&quot;{region_num}_{year}: Доля отказов&quot;, show_figure=False, ) return [_decisions_total_hist, _rejections_share_hist] plots_list = plot_hist_by_region(2021, 50, kadeng_stat_agg) pandas_bokeh.plot_grid([plots_list], width=400, height=300) . Column(id&nbsp;=&nbsp;&#39;2401&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[ToolbarBox(id=&#39;2400&#39;, ...), GridBox(id=&#39;2398&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) Для жителей Московской области или москвичей, кто хотел бы решить земельные вопросы, статистика неутешительная. &quot;Средний&quot; кадастровый инженер получил в 2021 году 98% отказов. . Определим лидеров и аутсайдеров среди кадастровых инженеров. Дальнейший анализ сделаем для данных по Московской области за последние 3 года (2019-2021). Нас интересует рэнкинг по количеству документов (больше - лучше) и доле отказов (больше - хуже). . years = [2019, 2020, 2021] region_num = &quot;50&quot; kadeng_stat_50 = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;].isin(years) ) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))] # Переведем в wide форму kadeng_stat_50_wide = kadeng_stat_50.pivot(index=[&quot;att_region&quot;, &quot;id&quot;], columns=[&quot;year&quot;,]) # Убираем мультииндекс и объединяем название колонок с годами kadeng_stat_50_wide.columns = [&#39;_&#39;.join((col[0],str(col[1]))) for col in kadeng_stat_50_wide.columns] kadeng_stat_50_wide.reset_index(inplace=True) # Дополним данными ФИО и аттестата кад.инженера kadeng_stat_50_wide = kadeng_stat_50_wide.merge(general_info_clean, how=&quot;left&quot;, left_on=&quot;id&quot;, right_on=&quot;id&quot;) kadeng_stat_50 = kadeng_stat_50.merge(general_info_clean, how=&quot;left&quot;, left_on=&quot;id&quot;, right_on=&quot;id&quot;) display(kadeng_stat_50_wide.head()) display(kadeng_stat_50.head()) . att_region_x id decisions_total_2019 decisions_total_2020 decisions_total_2021 acceptions_total_2019 acceptions_total_2020 acceptions_total_2021 rejections_total_2019 rejections_total_2020 ... email reg_number_sro att_number att_date first_name last_name middle_name att_region_y geoname_name iso_code . 0 50 | 804422 | 424 | 241 | 107 | 316 | 124 | -12 | 108 | 117 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 1 50 | 804463 | 398 | 69 | 75 | 166 | 6 | -16 | 232 | 63 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 2 50 | 804474 | 26 | 10 | 0 | 15 | 7 | 0 | 11 | 3 | ... | ss00@km.ru | NaN | 50-13-920 | 2013-07-24 | Марина | Анохина | Владимировна | 50 | Moscow Oblast | RU-MOS | . 3 50 | 804484 | 161 | 163 | 184 | 37 | 75 | -22 | 124 | 88 | ... | RasadkinaAnna@inbox.ru | NaN | 50-11-659 | 2011-07-05 | Анна | Безрукавникова | Павловна | 50 | Moscow Oblast | RU-MOS | . 4 50 | 804581 | 390 | 151 | 84 | 179 | 110 | -24 | 211 | 41 | ... | kate-wolf@yandex.ru | NaN | 50-11-302 | 2011-01-25 | Екатерина | Волкова | Леонидовна | 50 | Moscow Oblast | RU-MOS | . 5 rows × 31 columns . att_region_x id year decisions_total acceptions_total rejections_total rejections_share acceptions_share full_name reg_number ... email reg_number_sro att_number att_date first_name last_name middle_name att_region_y geoname_name iso_code . 0 50 | 804422 | 2019 | 424 | 316 | 108 | 0.254717 | 0.745283 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 1 50 | 804422 | 2020 | 241 | 124 | 117 | 0.485477 | 0.514523 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 2 50 | 804422 | 2021 | 107 | -12 | 119 | 1.112150 | -0.112150 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 3 50 | 804463 | 2019 | 398 | 166 | 232 | 0.582915 | 0.417085 | Абрамов Дмитрий Александрович | 3064 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 4 50 | 804463 | 2020 | 69 | 6 | 63 | 0.913043 | 0.086957 | Абрамов Дмитрий Александрович | 3064 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 5 rows × 22 columns . from bokeh.models import HoverTool from bokeh.plotting import figure, show from bokeh.models import NumeralTickFormatter from bokeh.plotting import ColumnDataSource, figure, output_file, show from bokeh.io import output_notebook, reset_output from bokeh.transform import linear_cmap from bokeh.palettes import Spectral6, Viridis3 cols_to_plot = [ &quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, &quot;full_name&quot;, &quot;att_number&quot;, &quot;att_date&quot;, &quot;year&quot;, ] #Use the field name of the column source mapper = linear_cmap(field_name=&#39;year&#39;, palette=Viridis3, low=2019 ,high=2021) source = ColumnDataSource(data=kadeng_stat_50.loc[:, cols_to_plot]) TOOLTIPS = [ (&quot;Год&quot;, &quot;@year&quot;), (&quot;ФИО&quot;, &quot;@full_name&quot;), (&quot;Всего решений&quot;, &quot;@decisions_total&quot;), (&quot;Доля отказов&quot;, &quot;@rejections_share{(0%)}&quot;), (&quot;Аттестат&quot;, &quot;@att_number&quot;), ] p = figure(width=800, height=400, tooltips=TOOLTIPS, title=&quot;Количество решений Росреестра: всего и отказов&quot;,) p.circle( &quot;rejections_total&quot;, &quot;decisions_total&quot;, source=source, color = mapper, legend_group = &quot;year&quot; ) p.legend.location = &quot;top_left&quot; p.xaxis.axis_label = &quot;Количество отказов&quot; p.xaxis.formatter = NumeralTickFormatter(format=&#39;0&#39;) p.yaxis.axis_label = &quot;Количество решений&quot; # Output to file / notebook reset_output() output_notebook() #output_file(&quot;toolbar.html&quot;) show(p) #show(p) # colormap = {2019: &quot;pink&quot;, 2020: &quot;green&quot;, 2021: &quot;blue&quot;} # colors = [colormap[x] for x in kadeng_stat_50[&quot;year&quot;]] # p = figure( # title=&quot;50: Деятельность отдельных кад.инженеров&quot;, # background_fill_color=&quot;#fafafa&quot;, # ) # # TOOLTIPS = [ # (&quot;ФИО&quot;, &quot;$full_name&quot;), # (&quot;Год&quot;, &quot;$year&quot;) # (&quot;Документов подано&quot;, &quot;&quot;) # (&quot;Аттестат&quot;, &quot;$att_number&quot;), # (&quot;Дата выдачи аттестата&quot;, &quot;$@desc&quot;), # ] # p.scatter( # kadeng_stat_50[&quot;rejections_share&quot;], # kadeng_stat_50[&quot;decisions_total&quot;], # color=colors, # fill_alpha=0.2, # size=10, # ) # # p.legend.location = &quot;top_left&quot; # # p.legend.title = &quot;Species&quot; # show(p) . Loading BokehJS ... cols_to_plot = [&quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, &quot;full_name&quot;, &quot;att_number&quot;, &quot;att_date&quot;, &quot;year&quot;, ] kadeng_stat_50.loc[:,cols_to_plot] . decisions_total acceptions_total rejections_total rejections_share full_name att_number att_date year . 0 424 | 316 | 108 | 0.254717 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2019 | . 1 241 | 124 | 117 | 0.485477 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2020 | . 2 107 | -12 | 119 | 1.112150 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2021 | . 3 398 | 166 | 232 | 0.582915 | Абрамов Дмитрий Александрович | 50-10-245 | 2010-12-28 | 2019 | . 4 69 | 6 | 63 | 0.913043 | Абрамов Дмитрий Александрович | 50-10-245 | 2010-12-28 | 2020 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 3487 288 | 223 | 65 | 0.225694 | Лазуков Виталий Николаевич | 50-11-471 | 2011-02-15 | 2020 | . 3488 165 | 29 | 136 | 0.824242 | Лазуков Виталий Николаевич | 50-11-471 | 2011-02-15 | 2021 | . 3489 837 | 788 | 49 | 0.058542 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2019 | . 3490 218 | 193 | 25 | 0.114679 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2020 | . 3491 323 | 181 | 142 | 0.439628 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2021 | . 3492 rows × 8 columns . len(slider_columns) len(slider_range) . 8 . import json from bokeh.io import output_file, output_notebook, show from bokeh.models import ColorBar, GeoJSONDataSource, LinearColorMapper from bokeh.palettes import brewer from bokeh.plotting import figure from bokeh.models import Range1d # Read data to json. merged_json = json.loads(points_to_map.to_json()) # Convert to String like object. json_data = json.dumps(merged_json) # Input GeoJSON source that contains features for plotting. geosource = GeoJSONDataSource(geojson=json_data) # Define a sequential multi-hue color palette. palette = brewer[&quot;YlGnBu&quot;][8] # Reverse color order so that dark blue is highest obesity. palette = palette[::-1] # Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors. color_mapper = LinearColorMapper(palette=palette, low=0, high=40, nan_color=&quot;#d9d9d9&quot;) # Define custom tick labels for color bar. # tick_labels = {&#39;0&#39;: &#39;0%&#39;, &#39;5&#39;: &#39;5%&#39;, &#39;10&#39;:&#39;10%&#39;, &#39;15&#39;:&#39;15%&#39;, &#39;20&#39;:&#39;20%&#39;, &#39;25&#39;:&#39;25%&#39;, &#39;30&#39;:&#39;30%&#39;,&#39;35&#39;:&#39;35%&#39;, &#39;40&#39;: &#39;&gt;40%&#39;} # Create color bar. color_bar = ColorBar( color_mapper=color_mapper, label_standoff=8, width=500, height=20, border_line_color=None, location=(0, 0), orientation=&quot;horizontal&quot;, ) # , major_label_overrides = tick_labels) # Create figure object. p = figure( title=&quot;Share of adults who are obese, 2016&quot;, plot_height=600, plot_width=950, toolbar_location=None, ) p.xgrid.grid_line_color = None p.ygrid.grid_line_color = None p.x_range = Range1d(20, 180) # Add patch renderer to figure. p.patches( &quot;xs&quot;, &quot;ys&quot;, source=geosource, fill_color={&quot;field&quot;: &quot;decisions_total&quot;, &quot;transform&quot;: color_mapper}, line_color=&quot;black&quot;, line_width=0.25, fill_alpha=1, ) # Specify figure layout. p.add_layout(color_bar, &quot;below&quot;) # Display figure inline in Jupyter Notebook. output_notebook() # Display figure. show(p) . ValueError Traceback (most recent call last) /Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb Cell 33&#39; in &lt;cell line: 11&gt;() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=7&#39;&gt;8&lt;/a&gt; from bokeh.models import Range1d &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=9&#39;&gt;10&lt;/a&gt; # Read data to json. &gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=10&#39;&gt;11&lt;/a&gt; merged_json = json.loads(points_to_map.to_json()) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=11&#39;&gt;12&lt;/a&gt; # Convert to String like object. &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=12&#39;&gt;13&lt;/a&gt; json_data = json.dumps(merged_json) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:750, in GeoDataFrame.to_json(self, na, show_bbox, drop_id, **kwargs) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=695&#39;&gt;696&lt;/a&gt; def to_json(self, na=&#34;null&#34;, show_bbox=False, drop_id=False, **kwargs): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=696&#39;&gt;697&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=697&#39;&gt;698&lt;/a&gt; Returns a GeoJSON representation of the ``GeoDataFrame`` as a string. &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=698&#39;&gt;699&lt;/a&gt; (...) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=746&#39;&gt;747&lt;/a&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=747&#39;&gt;748&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=748&#39;&gt;749&lt;/a&gt; return json.dumps( --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=749&#39;&gt;750&lt;/a&gt; self._to_geo(na=na, show_bbox=show_bbox, drop_id=drop_id), **kwargs &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=750&#39;&gt;751&lt;/a&gt; ) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:897, in GeoDataFrame._to_geo(self, **kwargs) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=888&#39;&gt;889&lt;/a&gt; def _to_geo(self, **kwargs): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=889&#39;&gt;890&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=890&#39;&gt;891&lt;/a&gt; Returns a python feature collection (i.e. the geointerface) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=891&#39;&gt;892&lt;/a&gt; representation of the GeoDataFrame. &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=892&#39;&gt;893&lt;/a&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=893&#39;&gt;894&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=894&#39;&gt;895&lt;/a&gt; geo = { &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=895&#39;&gt;896&lt;/a&gt; &#34;type&#34;: &#34;FeatureCollection&#34;, --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=896&#39;&gt;897&lt;/a&gt; &#34;features&#34;: list(self.iterfeatures(**kwargs)), &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=897&#39;&gt;898&lt;/a&gt; } &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=899&#39;&gt;900&lt;/a&gt; if kwargs.get(&#34;show_bbox&#34;, False): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=900&#39;&gt;901&lt;/a&gt; geo[&#34;bbox&#34;] = tuple(self.total_bounds) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:838, in GeoDataFrame.iterfeatures(self, na, show_bbox, drop_id) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=834&#39;&gt;835&lt;/a&gt; geometries = np.array(self[self._geometry_column_name], copy=False) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=836&#39;&gt;837&lt;/a&gt; if not self.columns.is_unique: --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=837&#39;&gt;838&lt;/a&gt; raise ValueError(&#34;GeoDataFrame cannot contain duplicated column names.&#34;) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=839&#39;&gt;840&lt;/a&gt; properties_cols = self.columns.difference([self._geometry_column_name]) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=841&#39;&gt;842&lt;/a&gt; if len(properties_cols) &gt; 0: &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=842&#39;&gt;843&lt;/a&gt; # convert to object to get python scalars. ValueError: GeoDataFrame cannot contain duplicated column names. . points_to_map.loc[points_to_map[&quot;att_region&quot;] == 50] . ID_0 ISO NAME_0 ID_1 NAME_1 HASC_1 CCN_1 CCA_1 TYPE_1 ENGTYPE_1 NL_NAME_1 VARNAME_1 geometry year att_region decisions_total acceptions_total rejections_total rejections_share . 49 188 | RUS | Russia | 50 | Novosibirsk | RU.NS | 0 | 0 | Oblast | Region | Новосибирская область | Novosibirskaya Oblast | POLYGON ((76.25723 57.20467, 76.42656 57.18681... | 2021.0 | 50 | 154293.0 | 41475.0 | 112818.0 | 0.731193 | .",
            "url": "https://evgeniypaskin.github.io/kadeng_stats/2022/05/20/publish_v2.html",
            "relUrl": "/2022/05/20/publish_v2.html",
            "date": " • May 20, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "import geopandas as gpd import hvplot import hvplot.pandas import numpy as np import pandas as pd import pandas_profiling import pandas_bokeh . dt_dict = { &quot;general_info&quot; : {&quot;path&quot; :&quot;./PARSED DATA/general.xlsx&quot;}, &quot;statistics_1&quot; : {&quot;path&quot; :&quot;./PARSED DATA/statistics_1.xlsx&quot;}, &quot;statistics_2&quot; : {&quot;path&quot; :&quot;./PARSED DATA/statistics_2.xlsx&quot;}, &quot;sro_membership&quot;: {&quot;path&quot; :&quot;./PARSED DATA/sro.xlsx&quot;}, &quot;penalties&quot;: {&quot;path&quot; :&quot;./PARSED DATA/discipline.xlsx&quot;}, } . for data_name, data_name_dict in dt_dict.items(): data_path = data_name_dict.get(&quot;path&quot;) data_raw = pd.read_excel(data_path) data_name_dict[&quot;data_raw&quot;] = data_raw display(data_raw.head(3)) display(data_raw.info()) . ID name attestat reg_number date_added date_sro email reg_number_sro . 0 826933 | Ёжиков Роман Дмитриевич | номер: 13-11-56_x000D_ n   дата выдачи: 07.... | 9624.0 | 03.03.2011 | 30.06.2016 | ezikoff@mail.ru | NaN | . 1 816193 | Ёжикова Анастасия Игоревна | номер: 23-15-1421_x000D_ n   дата выдачи: 1... | 34341.0 | 01.07.2015 | 26.11.2016 | NaN | NaN | . 2 817155 | Ёлчин Евгений Владиславович | номер: 50-11-720_x000D_ n   дата выдачи: 27... | 16912.0 | 06.10.2011 | 28.06.2016 | yolchin@mail.ru | NaN | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 40047 entries, 0 to 40046 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 ID 40047 non-null int64 1 name 39907 non-null object 2 attestat 39843 non-null object 3 reg_number 39907 non-null float64 4 date_added 31652 non-null object 5 date_sro 19166 non-null object 6 email 38261 non-null object 7 reg_number_sro 5913 non-null object dtypes: float64(1), int64(1), object(6) memory usage: 2.4+ MB . None . ID year period total_decisions rejections_27fz decisions_mistakes decisions_suspensions . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 85900 entries, 0 to 85899 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 ID 85900 non-null int64 1 year 85900 non-null int64 2 period 85900 non-null int64 3 total_decisions 85900 non-null int64 4 rejections_27fz 85900 non-null int64 5 decisions_mistakes 85900 non-null int64 6 decisions_suspensions 85900 non-null int64 dtypes: int64(7) memory usage: 4.6 MB . None . ID year period total_decisions rejections_27fz decisions_mistakes decisions_suspensions . 0 826933 | 2014 | 9 | 136 | 1 | 2 | 0 | . 1 826933 | 2014 | 12 | 215 | 2 | 2 | 0 | . 2 826933 | 2015 | 3 | 57 | 2 | 2 | 0 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1048575 entries, 0 to 1048574 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 ID 1048575 non-null int64 1 year 1048575 non-null int64 2 period 1048575 non-null int64 3 total_decisions 1048575 non-null int64 4 rejections_27fz 1048575 non-null int64 5 decisions_mistakes 1048575 non-null int64 6 decisions_suspensions 1048575 non-null int64 dtypes: int64(7) memory usage: 56.0 MB . None . ID sro_name date_sro_incl date_sro_excl sro_excl_reason . 0 826933 | Ассоциация Саморегулируемая организация &quot;Межре... | 30.06.2016 | NaN | NaN | . 1 816193 | Саморегулируемая организация Ассоциация &quot;Неком... | 26.11.2016 | NaN | NaN | . 2 817155 | Ассоциация &quot;Гильдия кадастровых инженеров&quot; | 28.06.2016 | NaN | NaN | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 37441 entries, 0 to 37440 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 ID 37441 non-null int64 1 sro_name 37441 non-null object 2 date_sro_incl 37246 non-null object 3 date_sro_excl 13322 non-null object 4 sro_excl_reason 13479 non-null object dtypes: int64(1), object(4) memory usage: 1.4+ MB . None . ID Мера ДВ Дата решения о применении меры ДВ Основание применения меры ДВ Дата начала ДВ Дата окончания ДВ . 0 824174 | Замечание | 03.12.2020 | Протокол ДК № 62д/12 | 03.12.2020 | 03.12.2020 | . 1 824174 | Замечание | 10.02.2022 | Протокол Дисциплинарной комиссии Ассоциации СР... | 10.02.2022 | 10.02.2022 | . 2 812881 | предписание устранить нарушение в срок до 11.0... | 12.05.2021 | Протокол заседания Дисциплинарного комитета А ... | 12.05.2021 | 11.06.2021 | . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 5358 entries, 0 to 5357 Data columns (total 6 columns): # Column Non-Null Count Dtype -- -- 0 ID 5358 non-null int64 1 Мера ДВ 5358 non-null object 2 Дата решения о применении меры ДВ 5358 non-null object 3 Основание применения меры ДВ 5358 non-null object 4 Дата начала ДВ 5143 non-null object 5 Дата окончания ДВ 4422 non-null object dtypes: int64(1), object(5) memory usage: 251.3+ KB . None . Необходимые шаги предобработки данных: . Таблица: Общая информация: . Сплит данных аттестата: att_number, att_date | Сплит ФИО: first_name, last_name , middle_name | reg_number: float -&gt; int | Коррекция типа данных для колонок с датами | Переименование колонок по словарю | . Таблица: Членство в СРО . Коррекция типа данных для колонок с датами | Переименование колонок по словарю | . Таблица: Диспицлинарные взыскания . Коррекция типа данных для колонок с датами | Переименование колонок по словарю | Перевод в нижний регистр тип взыскания | . Таблица: Статистика: . Объединение 2х файлов статистики деятельности | Создание колонки statistics_period из year + period (квартал) в формате дат pandas | Переименование колонок по словарю | . Определим словарь для единообразного переименования колонок, а также функции для очистки даннных в разных датасетах . rename_columns_dict = { # Все таблицы &quot;ID&quot;:&quot;id&quot;, # Таблица дисциплинарных взысканий &quot;Мера ДВ&quot;: &quot;penalty_type&quot;, &quot;Дата решения о применении меры ДВ&quot;: &quot;penalty_decision_date&quot;, &quot;Основание применения меры ДВ&quot;: &quot;penalty_decision_reason&quot;, &quot;Дата начала ДВ&quot;: &quot;penalty_start_date&quot;, &quot;Дата окончания ДВ&quot;: &quot;penalty_end_date&quot;, # Таблица членства в СРО &quot;date_sro_incl&quot; : &quot;sro_inclusion_date&quot;, &quot;date_sro_excl&quot; : &quot;sro_exclusion_date&quot;, &quot;sro_excl_reason&quot;: &quot;sro_exclusion_reason&quot;, # Таблица общей информации &quot;date_added&quot; : &quot;added_date&quot;, &quot;date_sro&quot;: &quot;sro_date&quot;, &quot;name&quot;: &quot;full_name&quot;, # Таблица статистики &quot;total_decisions&quot;: &quot;decisions_total&quot;, &quot;rejections_27fz&quot;: &quot;decisions_27fz&quot;, } . def clean_general_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw general info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Разбираем attestat на необходимые поля .assign(att_number = lambda x: x.attestat.str.split(&quot;_&quot;).str[0])#.str.split(&quot; &quot;).str[1]) .assign(att_number = lambda x: x.att_number.str.split(&quot; &quot;).str[1]) .assign(att_date = lambda x: x.attestat.str.split(&quot;дата выдачи: &quot;).str[1]) .drop(&quot;attestat&quot;, axis=1) # Разбираем ФИО. При такой реализации могут быть ошибки в нестандартных именах .assign(first_name = lambda x: x.name.str.split(&quot; &quot;).str[1]) .assign(last_name = lambda x: x.name.str.split(&quot; &quot;).str[0]) .assign(middle_name = lambda x: x.name.str.split(&quot; &quot;).str[-1]) # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат данных .assign(reg_number = lambda x: x.reg_number.astype(&quot;Int64&quot;)) # Меняем формат дат .assign(added_date = lambda x: pd.to_datetime(x.added_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) .assign(sro_date = lambda x: pd.to_datetime(x.sro_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) .assign(att_date = lambda x: pd.to_datetime(x.att_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;ignore&quot;).dt.date) ) return df_clean def clean_sro_membership_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw SRO membership info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат дат .assign(sro_inclusion_date = lambda x: pd.to_datetime(x.sro_inclusion_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(sro_exclusion_date = lambda x: pd.to_datetime(x.sro_exclusion_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) ) return df_clean def clean_penalties_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw penalties info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Меняем формат дат .assign(penalty_decision_date = lambda x: pd.to_datetime(x.penalty_decision_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(penalty_start_date = lambda x: pd.to_datetime(x.penalty_start_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) .assign(penalty_end_date = lambda x: pd.to_datetime(x.penalty_end_date, format=&quot;%d.%m.%Y&quot;, errors=&quot;coerce&quot;).dt.date) # Переводим в нижний регистр тип взыскания .assign(penalty_type = lambda x: x.penalty_type.str.lower()) ) return df_clean def clean_statistics_df(df_to_clean:pd.DataFrame) -&gt; pd.DataFrame: &quot;&quot;&quot;Function to clean raw statistics info. Returns cleaned df&quot;&quot;&quot; df_clean = ( df_to_clean.copy() # Переименовываем колонки по словарю .rename(columns=rename_columns_dict) # Создадим колонку с периодами деятельности .assign(statistics_period = lambda x: x.period.astype(str)+ &quot;-&quot;+ x.year.astype(str)) .assign(statistics_period = lambda x: (pd.to_datetime(x.statistics_period, format=&quot;%m-%Y&quot;,errors=&quot;coerce&quot;) + pd.offsets.MonthEnd(0)).dt.date) .assign(quarter = lambda x: (x.period/3).astype(&quot;int64&quot;)) ) return df_clean . dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] = clean_general_df(dt_dict[&quot;general_info&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics_1&quot;][&quot;data_clean&quot;] = clean_statistics_df(dt_dict[&quot;statistics_1&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics_2&quot;][&quot;data_clean&quot;] = clean_statistics_df(dt_dict[&quot;statistics_2&quot;][&quot;data_raw&quot;]) dt_dict[&quot;sro_membership&quot;][&quot;data_clean&quot;] = clean_sro_membership_df(dt_dict[&quot;sro_membership&quot;][&quot;data_raw&quot;]) dt_dict[&quot;penalties&quot;][&quot;data_clean&quot;] = clean_penalties_df(dt_dict[&quot;penalties&quot;][&quot;data_raw&quot;]) dt_dict[&quot;statistics&quot;] = {&quot;data_clean&quot;: pd.concat([dt_dict[&quot;statistics_1&quot;][&quot;data_clean&quot;], dt_dict[&quot;statistics_2&quot;][&quot;data_clean&quot;], ])} for k, v in dt_dict.items(): display(v.get(&quot;data_clean&quot;).head(3)) . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name . 0 826933 | Ёжиков Роман Дмитриевич | 9624 | 2011-03-03 | 2016-06-30 | ezikoff@mail.ru | NaN | 13-11-56 | 2011-02-07 | Роман | Ёжиков | Дмитриевич | . 1 816193 | Ёжикова Анастасия Игоревна | 34341 | 2015-07-01 | 2016-11-26 | NaN | NaN | 23-15-1421 | 2015-06-17 | Анастасия | Ёжикова | Игоревна | . 2 817155 | Ёлчин Евгений Владиславович | 16912 | 2011-10-06 | 2016-06-28 | yolchin@mail.ru | NaN | 50-11-720 | 2011-09-27 | Евгений | Ёлчин | Владиславович | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 826933 | 2014 | 9 | 136 | 1 | 2 | 0 | 2014-09-30 | 3 | . 1 826933 | 2014 | 12 | 215 | 2 | 2 | 0 | 2014-12-31 | 4 | . 2 826933 | 2015 | 3 | 57 | 2 | 2 | 0 | 2015-03-31 | 1 | . id sro_name sro_inclusion_date sro_exclusion_date sro_exclusion_reason . 0 826933 | Ассоциация Саморегулируемая организация &quot;Межре... | 2016-06-30 | NaT | NaN | . 1 816193 | Саморегулируемая организация Ассоциация &quot;Неком... | 2016-11-26 | NaT | NaN | . 2 817155 | Ассоциация &quot;Гильдия кадастровых инженеров&quot; | 2016-06-28 | NaT | NaN | . id penalty_type penalty_decision_date penalty_decision_reason penalty_start_date penalty_end_date . 0 824174 | замечание | 2020-12-03 | Протокол ДК № 62д/12 | 2020-12-03 | 2020-12-03 | . 1 824174 | замечание | 2022-02-10 | Протокол Дисциплинарной комиссии Ассоциации СР... | 2022-02-10 | 2022-02-10 | . 2 812881 | предписание устранить нарушение в срок до 11.0... | 2021-05-12 | Протокол заседания Дисциплинарного комитета А ... | 2021-05-12 | 2021-06-11 | . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | . &#1040;&#1085;&#1072;&#1083;&#1080;&#1079; . Посмотрим внимательнее на признак &quot;Номер аттестата&quot; att_number и попробуем понять, значат ли что-то цифры его составляющие. Больше всего мы бы хотели вытащить информацию о регионах выдачи аттестатов и, может быть, одна из цифр кодирует регион. Если это так, то регионов должно быть около 85, а максимальное количество инженеров ожидается в 50-м, 77-м, 78-м регионах . _att_number_df = dt_dict[&quot;general_info&quot;].get(&quot;data_clean&quot;)[&quot;att_number&quot;] _att_number_df = _att_number_df.str.split(&quot;-&quot;, expand=True) _att_number_df = _att_number_df.dropna() _att_number_df = _att_number_df.astype(&quot;int64&quot;, errors=&quot;raise&quot;) _att_number_df = _att_number_df.rename(columns={0: &quot;smt_0&quot;, 1: &quot;smt_1&quot;, 2: &quot;smt_2&quot;}) display(_att_number_df[&quot;smt_0&quot;].nunique()) display(_att_number_df[&quot;smt_1&quot;].nunique()) display(_att_number_df[&quot;smt_2&quot;].nunique()) . 83 . 7 . 1577 . Отлично! Гипотеза пока не опровержена. . Количество уникальных объектов первой части атт.номера близко кол-ву субъектов рф | Вторая часть номера тоже представляет интерес: уникальных значений всего 7. Но что это может быть - пока не понятно | . Проверим количество аттестатов по предполагаемому признаку региона . pd.set_option(&quot;plotting.backend&quot;, &quot;hvplot&quot;) # Посчитаем количество _df = _att_number_df[&quot;smt_0&quot;].value_counts().sort_values(ascending=True) # Выберем и пометим первые и последние 10 значений n_to_show = 10 _df = ( pd.DataFrame(_df.iloc[np.r_[0:n_to_show, -n_to_show:0]]) .reset_index() .rename(columns={&quot;index&quot;: &quot;region&quot;, &quot;smt_0&quot;: &quot;attestats_count&quot;}) ) _df[&quot;rating&quot;] = f&quot;Top-{n_to_show}&quot; _df.loc[: n_to_show - 1, &quot;rating&quot;] = f&quot;Bottom-{n_to_show}&quot; # Выведем график _df.hvplot.barh( x=&quot;region&quot;, y=&quot;attestats_count&quot;, color=&quot;rating&quot;, cmap=[&quot;pink&quot;, &quot;blue&quot;], title=&quot;Количество аттестатов в top/bottom-10 регионах&quot;, legend=&quot;right&quot;, ) . Гипотеза о том, что в номере аттестата закодирован регион выдачи - подтвердилась. . Наибольшее количество аттестатов выдано в Москве | Удивительно, но на 2-м и 3-м месте, обгоняя Московскую Область, находятся Краснодарский край и Республика Башкортостан | . Дополним очищенный датасет с основной информацией по кадастровым инженерам данными о регионе. Для удобства дальнейшей интерпретации численных обозначений регионов скачаем &quot;подсказку&quot; . region_naming = pd.read_csv( &quot;https://raw.githubusercontent.com/hflabs/region/master/region.csv&quot;, dtype=object, ) # Достаем необходимые поля из таблицы регионов geoname_df = region_naming.loc[:, [&quot;kladr_id&quot;, &quot;geoname_name&quot;, &quot;iso_code&quot;]] geoname_df[&quot;code&quot;] = geoname_df[&quot;kladr_id&quot;].str[0:2] #geoname_df[&quot;iso_code&quot;] = geoname_df[&quot;iso_code&quot;].str.replace(&quot;-&quot;, &quot;.&quot;) display(geoname_df.head(3)) # Смерджим данные в датафрейм с основной информацией general_info_clean = dt_dict[&quot;general_info&quot;].get(&quot;data_clean&quot;).copy() general_info_clean[&quot;att_region&quot;] = ( general_info_clean[&quot;att_number&quot;].str.split(&quot;-&quot;, expand=False).str[0] ) general_info_clean = general_info_clean.merge( geoname_df[[&quot;geoname_name&quot;, &quot;code&quot;, &quot;iso_code&quot;]], how=&#39;left&#39;, left_on=&quot;att_region&quot;, right_on=&quot;code&quot;, ).drop(&quot;code&quot;, axis=1) # Посмотрим на результат и сохраним в словаре с данными display(general_info_clean.head(3)) dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] = general_info_clean . kladr_id geoname_name iso_code code . 0 0100000000000 | Adygeya Republic | RU-AD | 01 | . 1 0200000000000 | Bashkortostan Republic | RU-BA | 02 | . 2 0300000000000 | Buryatiya Republic | RU-BU | 03 | . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name att_region geoname_name iso_code . 0 826933 | Ёжиков Роман Дмитриевич | 9624 | 2011-03-03 | 2016-06-30 | ezikoff@mail.ru | NaN | 13-11-56 | 2011-02-07 | Роман | Ёжиков | Дмитриевич | 13 | Mordoviya Republic | RU-MO | . 1 816193 | Ёжикова Анастасия Игоревна | 34341 | 2015-07-01 | 2016-11-26 | NaN | NaN | 23-15-1421 | 2015-06-17 | Анастасия | Ёжикова | Игоревна | 23 | Krasnodarskiy | RU-KDA | . 2 817155 | Ёлчин Евгений Владиславович | 16912 | 2011-10-06 | 2016-06-28 | yolchin@mail.ru | NaN | 50-11-720 | 2011-09-27 | Евгений | Ёлчин | Владиславович | 50 | Moscow Oblast | RU-MOS | . region_naming.head() . name type name_with_type federal_district kladr_id fias_id okato oktmo tax_office postal_code iso_code timezone geoname_code geoname_id geoname_name . 0 Адыгея | Респ | Респ Адыгея | Южный | 0100000000000 | d8327a56-80de-4df2-815c-4f6ab1224c50 | 79000000000 | 79000000 | 0100 | 385000 | RU-AD | UTC+3 | RU.01 | 584222 | Adygeya Republic | . 1 Башкортостан | Респ | Респ Башкортостан | Приволжский | 0200000000000 | 6f2cbfd8-692a-4ee4-9b16-067210bde3fc | 80000000000 | 80000000 | 0200 | 452000 | RU-BA | UTC+5 | RU.08 | 578853 | Bashkortostan Republic | . 2 Бурятия | Респ | Респ Бурятия | Дальневосточный | 0300000000000 | a84ebed3-153d-4ba9-8532-8bdf879e1f5a | 81000000000 | 81000000 | 0300 | 671000 | RU-BU | UTC+8 | RU.11 | 2050915 | Buryatiya Republic | . 3 Алтай | Респ | Респ Алтай | Сибирский | 0400000000000 | 5c48611f-5de6-4771-9695-7e36a4e7529d | 84000000000 | 84000000 | 0400 | 649000 | RU-AL | UTC+7 | RU.03 | 1506272 | Altai | . 4 Дагестан | Респ | Респ Дагестан | Северо-Кавказский | 0500000000000 | 0bb7fa19-736d-49cf-ad0e-9774c4dae09b | 82000000000 | 82000000 | 0500 | 368000 | RU-DA | UTC+3 | RU.17 | 567293 | Dagestan | . _df = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] _df.loc[(_df[&quot;last_name&quot;]==&quot;Иванова&quot;) &amp; (_df[&quot;first_name&quot;]==&quot;Екатерина&quot;) ] . id full_name reg_number added_date sro_date email reg_number_sro att_number att_date first_name last_name middle_name att_region geoname_name iso_code . 12763 839234 | Иванова Екатерина Алексеевна | 23076 | 2012-11-21 | 2016-06-02 | NaN | NaN | 69-12-528 | 2012-11-07 | Екатерина | Иванова | Алексеевна | 69 | Tver Oblast | RU-TVE | . 12807 833816 | Иванова Екатерина Андреевна | 34311 | 2015-06-26 | 2016-11-17 | katis05@mail.ru | 1021 | 77-15-115 | 2015-05-29 | Екатерина | Иванова | Андреевна | 77 | Moscow | RU-MOW | . 12818 813232 | Иванова Екатерина Валентиновна | 16218 | 2011-08-30 | NaT | geo.centr@mail.ru | 32 | 50-11-689 | 2011-08-23 | Екатерина | Иванова | Валентиновна | 50 | Moscow Oblast | RU-MOS | . 12883 839340 | Иванова Екатерина Николаевна | 1312 | 2010-12-17 | NaT | katerina_perm_23@mail.ru | 260 | 59-10-91 | 2010-12-09 | Екатерина | Иванова | Николаевна | 59 | Perm | RU-PER | . Проанализируем статистику деятельности кад.инженеров во времени: . Посчитаем суммарное количество отказов по всем причинам | Посчитаем долю отказов | . (!) Так как обработка документов Росреестром растянуто во времени, могут быть кварталы, когда количество полученных в периоде отказов (по сути, по поданным ранее документам) превышает количество поданных в периоде документов . statistics_df = dt_dict[&quot;statistics&quot;][&quot;data_clean&quot;] cols_to_sum = [&quot;decisions_27fz&quot;, &quot;decisions_mistakes&quot;, &quot;decisions_suspensions&quot;] statistics_df[&quot;rejections_total&quot;] = statistics_df[cols_to_sum].sum(axis=1) statistics_df[&quot;acceptions_total&quot;] = statistics_df[&quot;decisions_total&quot;] - statistics_df[&quot;rejections_total&quot;] statistics_df[&quot;rejections_share&quot;] = ( statistics_df[&quot;rejections_total&quot;] / statistics_df[&quot;decisions_total&quot;] ) statistics_df[&quot;acceptions_share&quot;] = ( statistics_df[&quot;acceptions_total&quot;] / statistics_df[&quot;decisions_total&quot;] ) display(statistics_df.head(3)) . id year period decisions_total decisions_27fz decisions_mistakes decisions_suspensions statistics_period quarter rejections_total acceptions_total rejections_share acceptions_share . 0 832760 | 2020 | 3 | 49 | 0 | 0 | 0 | 2020-03-31 | 1 | 0 | 49 | 0.000000 | 1.000000 | . 1 832760 | 2020 | 6 | 135 | 0 | 0 | 8 | 2020-06-30 | 2 | 8 | 127 | 0.059259 | 0.940741 | . 2 832760 | 2020 | 9 | 177 | 0 | 0 | 12 | 2020-09-30 | 3 | 12 | 165 | 0.067797 | 0.932203 | . Посмотрим на агрегированную статистику отказов во времени. Так как отказы Росрееста получаются с временным лагом, возможна ситуация, когда доля отказов &gt; 1. . _df = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() (_df[[&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;statistics_period&quot;]] .groupby(&quot;statistics_period&quot;) .sum() .hvplot.bar( stacked=True, x=&quot;statistics_period&quot;, yformatter=&#39;%.0e&#39;, width = 1000, title = &quot;Поквартальное (накопленное за год) количество одобренных и отвегнутых документов&quot;, ylabel = &quot;Документов&quot;, xlabel = &quot;&quot;, rot=90)) . Мы видим, что с начала 2019 года явно поменялась структура и/или подход к проверке документов: при сохранении общей динамики и сезонности, количество отказов возрасло многократно. В вики ведомства ничего примечательного относительно 2018-2019 годов не написано, да и на TAdvisor тоже ничего примечательного в данные периоды. . Посмотрим на динамику доли отказов . _df2 = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() _df2 = _df2[[&quot;decisions_total&quot;, &quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;statistics_period&quot;]].groupby(&quot;statistics_period&quot;).agg(&quot;sum&quot;) # Пересчитаем доли на агрегатах _df2[&quot;rejections_share&quot;] = ( _df2[&quot;rejections_total&quot;] / _df2[&quot;decisions_total&quot;] ) _df2[&quot;acceptions_share&quot;] = ( _df2[&quot;acceptions_total&quot;] / _df2[&quot;decisions_total&quot;] ) _df2.hvplot.bar( stacked=True, x=&quot;statistics_period&quot;, y=[&quot;acceptions_share&quot;, &quot;rejections_share&quot;,], width = 1000, title = &quot;Поквартальная доля одобренных и отвегнутых документов&quot;, ylabel = &quot;Доля документов&quot;, xlabel = &quot;&quot;, rot=90) . Мы видим, что начиная с 2019 года, за исключением одного квартала, доля отклоненных документов уверенно превышает 10%. А ведь эти документы подает не кто-то прохожий с улицы, а аттестованные &quot;профессионалы&quot; кадастровой деятельности. Если представить, что с таким уровнем сервиса (где доля отказов &gt;10%) работает коммерческая компания - то незавидной, недолгой и печальной кажется ее судьба, но монопольное положение Росреестра и его кадастровых инженеров это позволяет. &quot;И пусть весь мир подождет&quot; (с) какая-то реклама . _df[&quot;statistics_period&quot;].head() . 0 2020-03-31 1 2020-06-30 2 2020-09-30 3 2020-12-31 4 2021-03-31 Name: statistics_period, dtype: object . import pandas as pd import requests import geopandas as gpd from osm2geojson import json2geojson overpass_url = &quot;http://overpass-api.de/api/interpreter&quot; overpass_query = &quot;&quot;&quot; [out:json]; rel[admin_level=4] [type=boundary] [boundary=administrative] [&quot;ISO3166-2&quot;~&quot;^RU&quot;]; out geom; &quot;&quot;&quot; response = requests.get(overpass_url, params={&#39;data&#39;: overpass_query}) response.raise_for_status() data = response.json() geojson_data = json2geojson(data) gdf_osm = gpd.GeoDataFrame.from_features(geojson_data) # Конвертируем словари тэгов в колонки df_tags = gdf_osm[&quot;tags&quot;].apply(pd.Series) # Определим, какие колонки оставить для дальнейшего анализа cols_keep = [] for col in list(df_tags.columns): if &quot;name:&quot; not in col: cols_keep.append(col) cols_keep.extend([&quot;name:en&quot;, &quot;name:ru&quot;]) # Получим финальный геодатафрейм с нужными колонками gdf_full = pd.concat([gdf_osm, df_tags.loc[:,cols_keep]], axis=1) display(gdf_full.head()) . geometry type id tags ISO3166-2 addr:country admin_level border_type boundary cadaster:code ... place source:population alt_name2 old_name gis-lab:status source:url country ref:en name:en name:ru . 0 MULTIPOLYGON (((35.14891 55.95777, 35.14850 55... | relation | 51490 | {&#39;ISO3166-2&#39;: &#39;RU-MOS&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-MOS | RU | 4 | region | administrative | 50 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Moscow Oblast | Московская область | . 1 MULTIPOLYGON (((38.67446 54.25787, 38.66852 54... | relation | 71950 | {&#39;ISO3166-2&#39;: &#39;RU-RYA&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-RYA | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Ryazan Oblast | Рязанская область | . 2 MULTIPOLYGON (((37.73038 52.60995, 37.72625 52... | relation | 72169 | {&#39;ISO3166-2&#39;: &#39;RU-LIP&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-LIP | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Lipetsk Oblast | Липецкая область | . 3 MULTIPOLYGON (((39.91569 52.70885, 39.92159 52... | relation | 72180 | {&#39;ISO3166-2&#39;: &#39;RU-TAM&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-TAM | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Tambov Oblast | Тамбовская область | . 4 MULTIPOLYGON (((38.14031 51.63704, 38.14045 51... | relation | 72181 | {&#39;ISO3166-2&#39;: &#39;RU-VOR&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-VOR | RU | 4 | region | administrative | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Voronezh Oblast | Воронежская область | . 5 rows × 54 columns . import shapely import warnings from shapely.errors import ShapelyDeprecationWarning warnings.filterwarnings(&quot;ignore&quot;, category=ShapelyDeprecationWarning) pd.set_option(&#39;plotting.backend&#39;, &#39;pandas_bokeh&#39;) gdf_full_mercator = gdf_full.set_crs(&#39;epsg:4326&#39;) output_notebook() gdf_full_mercator.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;], title=&quot;Пустая карта РФ&quot;, xlim=[20, 180], ylim=[40, 80], ) . NameError Traceback (most recent call last) /Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb Cell 31&#39; in &lt;cell line: 9&gt;() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=5&#39;&gt;6&lt;/a&gt; pd.set_option(&#39;plotting.backend&#39;, &#39;pandas_bokeh&#39;) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=7&#39;&gt;8&lt;/a&gt; gdf_full_mercator = gdf_full.set_crs(&#39;epsg:4326&#39;) -&gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=8&#39;&gt;9&lt;/a&gt; output_notebook() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=9&#39;&gt;10&lt;/a&gt; gdf_full_mercator.plot_bokeh( &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=10&#39;&gt;11&lt;/a&gt; figsize = (1000, 600), &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=11&#39;&gt;12&lt;/a&gt; simplify_shapes=20000, (...) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=16&#39;&gt;17&lt;/a&gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000034?line=17&#39;&gt;18&lt;/a&gt; ) NameError: name &#39;output_notebook&#39; is not defined . _df = statistics_df.replace([np.inf, -np.inf], np.nan, inplace=False).dropna() _df_general = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] _df = _df.merge(_df_general, how=&quot;left&quot;, on=&quot;id&quot;) _df.head(3) _df3 = (_df[[&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;year&quot;, &quot;att_region&quot;,&quot;iso_code&quot;]] .groupby([&quot;year&quot;, &quot;iso_code&quot;]) .sum()) # Пересчитаем доли на агрегатах _df3[&quot;rejections_share&quot;] = ( _df3[&quot;rejections_total&quot;] / _df3[&quot;decisions_total&quot;] ) _df2[&quot;acceptions_share&quot;] = ( _df3[&quot;acceptions_total&quot;] / _df3[&quot;decisions_total&quot;] ) annual_reg_stat = _df3.reset_index() annual_reg_stat . year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 2014 | RU-AD | 90406 | 88318 | 2088 | 0.023096 | . 1 2014 | RU-AL | 18140 | 17853 | 287 | 0.015821 | . 2 2014 | RU-ALT | 77748 | 76185 | 1563 | 0.020103 | . 3 2014 | RU-AMU | 61431 | 60253 | 1178 | 0.019176 | . 4 2014 | RU-ARK | 45471 | 45277 | 194 | 0.004266 | . ... ... | ... | ... | ... | ... | ... | . 651 2021 | RU-VOR | 136037 | 127645 | 8392 | 0.061689 | . 652 2021 | RU-YAN | 7599 | 7502 | 97 | 0.012765 | . 653 2021 | RU-YAR | 62378 | 47058 | 15320 | 0.245599 | . 654 2021 | RU-YEV | 1232 | 1128 | 104 | 0.084416 | . 655 2021 | RU-ZAB | 26361 | 18298 | 8063 | 0.305869 | . 656 rows × 6 columns . reg_stat_2021 = annual_reg_stat.loc[annual_reg_stat[&quot;year&quot;]==2021,] reg_stat_2021 = reg_stat_2021.replace(&quot;&quot;,np.nan).dropna() #display(reg_stat_2021.head(3)) #display(gdf_full_mercator.head(3)) points_to_map = gdf_full_mercator.merge(reg_stat_2021, how=&quot;left&quot;, left_on=&quot;ISO3166-2&quot;, right_on=&quot;iso_code&quot;) #Replace NaN values to string &#39;No data&#39;. points_to_map.loc[:,[&quot;year&quot;,&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;rejections_share&quot;]].fillna(&#39;No data&#39;, inplace = True) points_to_map.head() . geometry type id tags ISO3166-2 addr:country admin_level border_type boundary cadaster:code ... country ref:en name:en name:ru year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 MULTIPOLYGON (((35.14891 55.95777, 35.14850 55... | relation | 51490 | {&#39;ISO3166-2&#39;: &#39;RU-MOS&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-MOS | RU | 4 | region | administrative | 50 | ... | NaN | NaN | Moscow Oblast | Московская область | 2021.0 | RU-MOS | 154293.0 | 41475.0 | 112818.0 | 0.731193 | . 1 MULTIPOLYGON (((38.67446 54.25787, 38.66852 54... | relation | 71950 | {&#39;ISO3166-2&#39;: &#39;RU-RYA&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-RYA | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Ryazan Oblast | Рязанская область | 2021.0 | RU-RYA | 91092.0 | 55574.0 | 35518.0 | 0.389913 | . 2 MULTIPOLYGON (((37.73038 52.60995, 37.72625 52... | relation | 72169 | {&#39;ISO3166-2&#39;: &#39;RU-LIP&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-LIP | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Lipetsk Oblast | Липецкая область | 2021.0 | RU-LIP | 37730.0 | 35923.0 | 1807.0 | 0.047893 | . 3 MULTIPOLYGON (((39.91569 52.70885, 39.92159 52... | relation | 72180 | {&#39;ISO3166-2&#39;: &#39;RU-TAM&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-TAM | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Tambov Oblast | Тамбовская область | 2021.0 | RU-TAM | 43556.0 | 39205.0 | 4351.0 | 0.099894 | . 4 MULTIPOLYGON (((38.14031 51.63704, 38.14045 51... | relation | 72181 | {&#39;ISO3166-2&#39;: &#39;RU-VOR&#39;, &#39;addr:country&#39;: &#39;RU&#39;, ... | RU-VOR | RU | 4 | region | administrative | NaN | ... | NaN | NaN | Voronezh Oblast | Воронежская область | 2021.0 | RU-VOR | 136037.0 | 127645.0 | 8392.0 | 0.061689 | . 5 rows × 60 columns . points_to_map.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;, &quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;rejections_share&quot;], dropdown = [&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;], title=&quot;2021&quot;, #colormap_uselog=True, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0.0a&quot;, xlim=[20, 180], ylim=[40, 80], ) . Column(id&nbsp;=&nbsp;&#39;6199&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[Select(id=&#39;6197&#39;, ...), Figure(id=&#39;6126&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) html_plot = points_to_map.plot_bokeh( figsize=(1000, 600), simplify_shapes=20000, hovertool_columns=[ &quot;name:ru&quot;, &quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, ], dropdown=[&quot;rejections_share&quot;], title=&quot;2021&quot;, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0%&quot;, return_html=True, xlim=[20, 180], ylim=[40, 80], ) # Export the HTML string to an external HTML file and show it: with open(&quot;test.html&quot;, &quot;w&quot;) as f: f.write(r&quot;&quot;&quot;&quot;&quot;&quot; + html_plot) . Визуализируем изменение доли отказов по регионам во времени. Ранее мы определили, что отказы &quot;поперли&quot; только с 2019 года. Соответственно статистику отобразим с этого момента. Для этого аггрегируем данные по годам/регионам и подготовим dataframe в wide формате для возможности отображения на географике. . display(annual_reg_stat.head()) statistics_df_wide = annual_reg_stat.pivot(index=&quot;iso_code&quot;, columns=[&quot;year&quot;,]) # Убираем мультииндекс и объединяем название колонок с годами statistics_df_wide.columns = [&#39;_&#39;.join((col[0],str(col[1]))) for col in statistics_df_wide.columns] statistics_df_wide.reset_index(inplace=True) statistics_df_wide.head() . year iso_code decisions_total acceptions_total rejections_total rejections_share . 0 2014 | RU-AD | 90406 | 88318 | 2088 | 0.023096 | . 1 2014 | RU-AL | 18140 | 17853 | 287 | 0.015821 | . 2 2014 | RU-ALT | 77748 | 76185 | 1563 | 0.020103 | . 3 2014 | RU-AMU | 61431 | 60253 | 1178 | 0.019176 | . 4 2014 | RU-ARK | 45471 | 45277 | 194 | 0.004266 | . iso_code decisions_total_2014 decisions_total_2015 decisions_total_2016 decisions_total_2017 decisions_total_2018 decisions_total_2019 decisions_total_2020 decisions_total_2021 acceptions_total_2014 ... rejections_total_2020 rejections_total_2021 rejections_share_2014 rejections_share_2015 rejections_share_2016 rejections_share_2017 rejections_share_2018 rejections_share_2019 rejections_share_2020 rejections_share_2021 . 0 RU-AD | 90406 | 113177 | 118257 | 80315 | 112610 | 101365 | 103318 | 103807 | 88318 | ... | 4630 | 6130 | 0.023096 | 0.015427 | 0.014392 | 0.004968 | 0.005621 | 0.051349 | 0.044813 | 0.059052 | . 1 RU-AL | 18140 | 29376 | 25000 | 18354 | 16829 | 15671 | 17242 | 28678 | 17853 | ... | 3532 | 2165 | 0.015821 | 0.012595 | 0.026600 | 0.002016 | 0.002020 | 0.102801 | 0.204849 | 0.075493 | . 2 RU-ALT | 77748 | 144355 | 121379 | 90999 | 109766 | 108327 | 69803 | 87897 | 76185 | ... | 2299 | 2257 | 0.020103 | 0.010911 | 0.006286 | 0.000835 | 0.001494 | 0.030934 | 0.032936 | 0.025678 | . 3 RU-AMU | 61431 | 80261 | 67780 | 53181 | 52099 | 39958 | 37574 | 45157 | 60253 | ... | 2347 | 3743 | 0.019176 | 0.026065 | 0.033579 | 0.005303 | 0.005240 | 0.076455 | 0.062463 | 0.082889 | . 4 RU-ARK | 45471 | 56499 | 51441 | 50128 | 42273 | 6389 | 14047 | 36597 | 45277 | ... | 3073 | 2699 | 0.004266 | 0.002584 | 0.001575 | 0.001875 | 0.003903 | 0.258256 | 0.218766 | 0.073749 | . 5 rows × 33 columns . statistics_df_wide.fillna(&#39;No data&#39;, inplace = True) # Combine statistics with geodataframe history_to_map = gdf_full_mercator.merge(statistics_df_wide, how=&quot;left&quot;, left_on=&quot;ISO3166-2&quot;, right_on=&quot;iso_code&quot;) #Specify slider columns: slider_columns = [&quot;rejections_share_%d&quot;%i for i in range(2019, 2022)] #Specify slider columns: slider_range = range(2019, 2022) history_to_map.plot_bokeh( figsize = (1000, 600), simplify_shapes=20000, hovertool_columns=[&quot;name:ru&quot;]+slider_columns, slider=slider_columns, slider_range=slider_range, slider_name=&quot;Year&quot;, title=&quot;Изменение доли отказов по регионам/годам&quot;, colormap=&quot;Viridis&quot;, colorbar_tick_format=&quot;0%&quot;, xlim=[20, 180], ylim=[40, 80], ) . Column(id&nbsp;=&nbsp;&#39;39722&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[Slider(id=&#39;39720&#39;, ...), Figure(id=&#39;39648&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) В 2020 году лидером по доле отказов была Астраханская область. &quot;Зарезано&quot; 90% поданных документов. В 2021 году в лидеры вырывается Московская область с 73% отказов. . Цифры колоссальные, если учесть сколько труда стоит за каждым из документов: . как минимум, несколько часов работы кадастрового инженера | сходить в МФЦ (в лучшем случае) и подать их | время сотрудников росреестра на формирование отказа | . Речь идет буквально о сотнях тысяч человекочасов не самых дешевых сотрудников ежегодно. В пустоту. Более того, за каждым отказом есть своя история расстройства семьи, неначатого бизнеса, затянутого инвестпроекта. . Система с такой долей отказов - ущербная, не работающая. Я могу лишь строить догадки, что такой уровень отказов выгоден самим кадастровым инженерам и повышает корупционную емкость кадастрового дела. Все при деле, работают. . &#1055;&#1088;&#1086;&#1072;&#1085;&#1072;&#1083;&#1080;&#1079;&#1080;&#1088;&#1091;&#1077;&#1084; &#1088;&#1072;&#1073;&#1086;&#1090;&#1091; &#1080;&#1085;&#1076;&#1080;&#1074;&#1080;&#1076;&#1091;&#1072;&#1083;&#1100;&#1085;&#1099;&#1093; &#1080;&#1085;&#1078;&#1077;&#1085;&#1077;&#1088;&#1086;&#1074; . kadeng_stat = statistics_df.copy() _df_general = dt_dict[&quot;general_info&quot;][&quot;data_clean&quot;] kadeng_stat = kadeng_stat.merge(_df_general, how=&quot;left&quot;, on=&quot;id&quot;) # Сгруппируем данные по кадастровым инженерам и годам kadeng_stat_agg = (kadeng_stat[[&quot;decisions_total&quot;,&quot;acceptions_total&quot;,&quot;rejections_total&quot;, &quot;year&quot;,&quot;id&quot;, &quot;att_region&quot;]] .groupby([&quot;att_region&quot;,&quot;id&quot;, &quot;year&quot;]) .sum()) # Пересчитаем доли на агрегатах kadeng_stat_agg[&quot;rejections_share&quot;] = ( kadeng_stat_agg[&quot;rejections_total&quot;] / kadeng_stat_agg[&quot;decisions_total&quot;] ) kadeng_stat_agg[&quot;acceptions_share&quot;] = ( kadeng_stat_agg[&quot;acceptions_total&quot;] / kadeng_stat_agg[&quot;decisions_total&quot;] ) kadeng_stat_agg.replace([np.inf, -np.inf], np.nan, inplace=True) kadeng_stat_agg = kadeng_stat_agg.reset_index(drop=False) . kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].describe() . id year decisions_total acceptions_total rejections_total rejections_share acceptions_share . count 39621.000000 | 39621.0 | 39621.000000 | 39621.00000 | 39621.000000 | 19987.000000 | 19987.000000 | . mean 824274.963580 | 2021.0 | 148.937760 | 129.19843 | 19.739330 | 0.247760 | 0.752240 | . std 11646.219417 | 0.0 | 436.343914 | 417.77568 | 65.527005 | 0.721857 | 0.721857 | . min 804223.000000 | 2021.0 | 0.000000 | -618.00000 | 0.000000 | 0.000000 | -36.666667 | . 25% 814220.000000 | 2021.0 | 0.000000 | 0.00000 | 0.000000 | 0.000000 | 0.769231 | . 50% 824232.000000 | 2021.0 | 1.000000 | 0.00000 | 0.000000 | 0.065068 | 0.934932 | . 75% 834221.000000 | 2021.0 | 155.000000 | 121.00000 | 10.000000 | 0.230769 | 1.000000 | . max 850716.000000 | 2021.0 | 28630.000000 | 28511.00000 | 3323.000000 | 37.666667 | 1.000000 | . decisions_total_hist = kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].plot_bokeh( kind=&quot;hist&quot;, bins = 100, y=[&quot;decisions_total&quot;], xlim=(0, 3000), vertical_xlabel=True, show_average = True, title = &quot;РФ_2021: Количество поданных документов&quot;, show_figure=False, ) rejections_share_hist = kadeng_stat_agg.loc[kadeng_stat_agg[&quot;year&quot;] == 2021].dropna().plot_bokeh( kind=&quot;hist&quot;, bins=np.arange(0, 3.5, 0.1), y=&quot;rejections_share&quot;, xlim=(0, 2), vertical_xlabel=True, show_average = True, title = &quot;РФ_2021: Доля отказов&quot;, show_figure=False, ) pandas_bokeh.plot_grid([[decisions_total_hist, rejections_share_hist]], width=400, height=300) . Column(id&nbsp;=&nbsp;&#39;2021&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[ToolbarBox(id=&#39;2020&#39;, ...), GridBox(id=&#39;2018&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) В 2021 году средняя доля отказов в группировке по кадастровым инженерам составляет почти 25% - вдвое больше, чем доля отказов по суммарному количеству документов. Гипотеза: есть небольшое количество &quot;супер-успешных&quot; кадастровых инженеров, с большим количеством поданных документов, которые &quot;проходят&quot; на отлично и которые вытягивают среднюю статистику . Посмотрим аналогичную статистику по Московской области . def plot_hist_by_region(year, region_num, kadeng_stat_agg): if isinstance(region_num, int): region_num=str(region_num) _decisions_total_hist = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;] == year) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))].plot_bokeh( kind=&quot;hist&quot;, bins = 30, y=[&quot;decisions_total&quot;], #xlim=(0, 3000), vertical_xlabel=True, show_average = True, title = f&quot;{region_num}_{year}: Количество поданных документов&quot;, #&quot;РФ 2021: Количество поданных документов&quot;, show_figure=False, ) _rejections_share_hist = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;] == year) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))].dropna().plot_bokeh( kind=&quot;hist&quot;, #bins=np.arange(0, 2.5, 0.1), bins = 30, y=[&quot;rejections_share&quot;], #xlim=(0, 2.5), vertical_xlabel=True, show_average = True, title = f&quot;{region_num}_{year}: Доля отказов&quot;, show_figure=False, ) return [_decisions_total_hist, _rejections_share_hist] plots_list = plot_hist_by_region(2021, 50, kadeng_stat_agg) pandas_bokeh.plot_grid([plots_list], width=400, height=300) . Column(id&nbsp;=&nbsp;&#39;2401&#39;, &hellip;)align&nbsp;=&nbsp;&#39;start&#39;,aspect_ratio&nbsp;=&nbsp;None,background&nbsp;=&nbsp;None,children&nbsp;=&nbsp;[ToolbarBox(id=&#39;2400&#39;, ...), GridBox(id=&#39;2398&#39;, ...)],css_classes&nbsp;=&nbsp;[],disabled&nbsp;=&nbsp;False,height&nbsp;=&nbsp;None,height_policy&nbsp;=&nbsp;&#39;auto&#39;,js_event_callbacks&nbsp;=&nbsp;{},js_property_callbacks&nbsp;=&nbsp;{},margin&nbsp;=&nbsp;(0, 0, 0, 0),max_height&nbsp;=&nbsp;None,max_width&nbsp;=&nbsp;None,min_height&nbsp;=&nbsp;None,min_width&nbsp;=&nbsp;None,name&nbsp;=&nbsp;None,rows&nbsp;=&nbsp;&#39;auto&#39;,sizing_mode&nbsp;=&nbsp;None,spacing&nbsp;=&nbsp;0,subscribed_events&nbsp;=&nbsp;[],syncable&nbsp;=&nbsp;True,tags&nbsp;=&nbsp;[],visible&nbsp;=&nbsp;True,width&nbsp;=&nbsp;None,width_policy&nbsp;=&nbsp;&#39;auto&#39;) Для жителей Московской области или москвичей, кто хотел бы решить земельные вопросы, статистика неутешительная. &quot;Средний&quot; кадастровый инженер получил в 2021 году 98% отказов. . Определим лидеров и аутсайдеров среди кадастровых инженеров. Дальнейший анализ сделаем для данных по Московской области за последние 3 года (2019-2021). Нас интересует рэнкинг по количеству документов (больше - лучше) и доле отказов (больше - хуже). . years = [2019, 2020, 2021] region_num = &quot;50&quot; kadeng_stat_50 = kadeng_stat_agg.loc[((kadeng_stat_agg[&quot;year&quot;].isin(years) ) &amp; (kadeng_stat_agg[&quot;att_region&quot;] == region_num))] # Переведем в wide форму kadeng_stat_50_wide = kadeng_stat_50.pivot(index=[&quot;att_region&quot;, &quot;id&quot;], columns=[&quot;year&quot;,]) # Убираем мультииндекс и объединяем название колонок с годами kadeng_stat_50_wide.columns = [&#39;_&#39;.join((col[0],str(col[1]))) for col in kadeng_stat_50_wide.columns] kadeng_stat_50_wide.reset_index(inplace=True) # Дополним данными ФИО и аттестата кад.инженера kadeng_stat_50_wide = kadeng_stat_50_wide.merge(general_info_clean, how=&quot;left&quot;, left_on=&quot;id&quot;, right_on=&quot;id&quot;) kadeng_stat_50 = kadeng_stat_50.merge(general_info_clean, how=&quot;left&quot;, left_on=&quot;id&quot;, right_on=&quot;id&quot;) display(kadeng_stat_50_wide.head()) display(kadeng_stat_50.head()) . att_region_x id decisions_total_2019 decisions_total_2020 decisions_total_2021 acceptions_total_2019 acceptions_total_2020 acceptions_total_2021 rejections_total_2019 rejections_total_2020 ... email reg_number_sro att_number att_date first_name last_name middle_name att_region_y geoname_name iso_code . 0 50 | 804422 | 424 | 241 | 107 | 316 | 124 | -12 | 108 | 117 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 1 50 | 804463 | 398 | 69 | 75 | 166 | 6 | -16 | 232 | 63 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 2 50 | 804474 | 26 | 10 | 0 | 15 | 7 | 0 | 11 | 3 | ... | ss00@km.ru | NaN | 50-13-920 | 2013-07-24 | Марина | Анохина | Владимировна | 50 | Moscow Oblast | RU-MOS | . 3 50 | 804484 | 161 | 163 | 184 | 37 | 75 | -22 | 124 | 88 | ... | RasadkinaAnna@inbox.ru | NaN | 50-11-659 | 2011-07-05 | Анна | Безрукавникова | Павловна | 50 | Moscow Oblast | RU-MOS | . 4 50 | 804581 | 390 | 151 | 84 | 179 | 110 | -24 | 211 | 41 | ... | kate-wolf@yandex.ru | NaN | 50-11-302 | 2011-01-25 | Екатерина | Волкова | Леонидовна | 50 | Moscow Oblast | RU-MOS | . 5 rows × 31 columns . att_region_x id year decisions_total acceptions_total rejections_total rejections_share acceptions_share full_name reg_number ... email reg_number_sro att_number att_date first_name last_name middle_name att_region_y geoname_name iso_code . 0 50 | 804422 | 2019 | 424 | 316 | 108 | 0.254717 | 0.745283 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 1 50 | 804422 | 2020 | 241 | 124 | 117 | 0.485477 | 0.514523 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 2 50 | 804422 | 2021 | 107 | -12 | 119 | 1.112150 | -0.112150 | Армеева Галина Алексеевна | 6598 | ... | 509-05-35@mail.ru | NaN | 50-11-300 | 2011-01-25 | Галина | Армеева | Алексеевна | 50 | Moscow Oblast | RU-MOS | . 3 50 | 804463 | 2019 | 398 | 166 | 232 | 0.582915 | 0.417085 | Абрамов Дмитрий Александрович | 3064 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 4 50 | 804463 | 2020 | 69 | 6 | 63 | 0.913043 | 0.086957 | Абрамов Дмитрий Александрович | 3064 | ... | 9440707@mail.ru | NaN | 50-10-245 | 2010-12-28 | Дмитрий | Абрамов | Александрович | 50 | Moscow Oblast | RU-MOS | . 5 rows × 22 columns . from bokeh.models import HoverTool from bokeh.plotting import figure, show from bokeh.models import NumeralTickFormatter from bokeh.plotting import ColumnDataSource, figure, output_file, show from bokeh.io import output_notebook, reset_output from bokeh.transform import linear_cmap from bokeh.palettes import Spectral6, Viridis3 cols_to_plot = [ &quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, &quot;full_name&quot;, &quot;att_number&quot;, &quot;att_date&quot;, &quot;year&quot;, ] #Use the field name of the column source mapper = linear_cmap(field_name=&#39;year&#39;, palette=Viridis3, low=2019 ,high=2021) source = ColumnDataSource(data=kadeng_stat_50.loc[:, cols_to_plot]) TOOLTIPS = [ (&quot;Год&quot;, &quot;@year&quot;), (&quot;ФИО&quot;, &quot;@full_name&quot;), (&quot;Всего решений&quot;, &quot;@decisions_total&quot;), (&quot;Доля отказов&quot;, &quot;@rejections_share{(0%)}&quot;), (&quot;Аттестат&quot;, &quot;@att_number&quot;), ] p = figure(width=800, height=400, tooltips=TOOLTIPS, title=&quot;Количество решений Росреестра: всего и отказов&quot;,) p.circle( &quot;rejections_total&quot;, &quot;decisions_total&quot;, source=source, color = mapper, legend_group = &quot;year&quot; ) p.legend.location = &quot;top_left&quot; p.xaxis.axis_label = &quot;Количество отказов&quot; p.xaxis.formatter = NumeralTickFormatter(format=&#39;0&#39;) p.yaxis.axis_label = &quot;Количество решений&quot; # Output to file / notebook reset_output() output_notebook() #output_file(&quot;toolbar.html&quot;) show(p) #show(p) # colormap = {2019: &quot;pink&quot;, 2020: &quot;green&quot;, 2021: &quot;blue&quot;} # colors = [colormap[x] for x in kadeng_stat_50[&quot;year&quot;]] # p = figure( # title=&quot;50: Деятельность отдельных кад.инженеров&quot;, # background_fill_color=&quot;#fafafa&quot;, # ) # # TOOLTIPS = [ # (&quot;ФИО&quot;, &quot;$full_name&quot;), # (&quot;Год&quot;, &quot;$year&quot;) # (&quot;Документов подано&quot;, &quot;&quot;) # (&quot;Аттестат&quot;, &quot;$att_number&quot;), # (&quot;Дата выдачи аттестата&quot;, &quot;$@desc&quot;), # ] # p.scatter( # kadeng_stat_50[&quot;rejections_share&quot;], # kadeng_stat_50[&quot;decisions_total&quot;], # color=colors, # fill_alpha=0.2, # size=10, # ) # # p.legend.location = &quot;top_left&quot; # # p.legend.title = &quot;Species&quot; # show(p) . Loading BokehJS ... cols_to_plot = [&quot;decisions_total&quot;, &quot;acceptions_total&quot;, &quot;rejections_total&quot;, &quot;rejections_share&quot;, &quot;full_name&quot;, &quot;att_number&quot;, &quot;att_date&quot;, &quot;year&quot;, ] kadeng_stat_50.loc[:,cols_to_plot] . decisions_total acceptions_total rejections_total rejections_share full_name att_number att_date year . 0 424 | 316 | 108 | 0.254717 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2019 | . 1 241 | 124 | 117 | 0.485477 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2020 | . 2 107 | -12 | 119 | 1.112150 | Армеева Галина Алексеевна | 50-11-300 | 2011-01-25 | 2021 | . 3 398 | 166 | 232 | 0.582915 | Абрамов Дмитрий Александрович | 50-10-245 | 2010-12-28 | 2019 | . 4 69 | 6 | 63 | 0.913043 | Абрамов Дмитрий Александрович | 50-10-245 | 2010-12-28 | 2020 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 3487 288 | 223 | 65 | 0.225694 | Лазуков Виталий Николаевич | 50-11-471 | 2011-02-15 | 2020 | . 3488 165 | 29 | 136 | 0.824242 | Лазуков Виталий Николаевич | 50-11-471 | 2011-02-15 | 2021 | . 3489 837 | 788 | 49 | 0.058542 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2019 | . 3490 218 | 193 | 25 | 0.114679 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2020 | . 3491 323 | 181 | 142 | 0.439628 | Ястребов Максим Сергеевич | 50-16-1169 | 2016-04-28 | 2021 | . 3492 rows × 8 columns . len(slider_columns) len(slider_range) . 8 . import json from bokeh.io import output_file, output_notebook, show from bokeh.models import ColorBar, GeoJSONDataSource, LinearColorMapper from bokeh.palettes import brewer from bokeh.plotting import figure from bokeh.models import Range1d # Read data to json. merged_json = json.loads(points_to_map.to_json()) # Convert to String like object. json_data = json.dumps(merged_json) # Input GeoJSON source that contains features for plotting. geosource = GeoJSONDataSource(geojson=json_data) # Define a sequential multi-hue color palette. palette = brewer[&quot;YlGnBu&quot;][8] # Reverse color order so that dark blue is highest obesity. palette = palette[::-1] # Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors. color_mapper = LinearColorMapper(palette=palette, low=0, high=40, nan_color=&quot;#d9d9d9&quot;) # Define custom tick labels for color bar. # tick_labels = {&#39;0&#39;: &#39;0%&#39;, &#39;5&#39;: &#39;5%&#39;, &#39;10&#39;:&#39;10%&#39;, &#39;15&#39;:&#39;15%&#39;, &#39;20&#39;:&#39;20%&#39;, &#39;25&#39;:&#39;25%&#39;, &#39;30&#39;:&#39;30%&#39;,&#39;35&#39;:&#39;35%&#39;, &#39;40&#39;: &#39;&gt;40%&#39;} # Create color bar. color_bar = ColorBar( color_mapper=color_mapper, label_standoff=8, width=500, height=20, border_line_color=None, location=(0, 0), orientation=&quot;horizontal&quot;, ) # , major_label_overrides = tick_labels) # Create figure object. p = figure( title=&quot;Share of adults who are obese, 2016&quot;, plot_height=600, plot_width=950, toolbar_location=None, ) p.xgrid.grid_line_color = None p.ygrid.grid_line_color = None p.x_range = Range1d(20, 180) # Add patch renderer to figure. p.patches( &quot;xs&quot;, &quot;ys&quot;, source=geosource, fill_color={&quot;field&quot;: &quot;decisions_total&quot;, &quot;transform&quot;: color_mapper}, line_color=&quot;black&quot;, line_width=0.25, fill_alpha=1, ) # Specify figure layout. p.add_layout(color_bar, &quot;below&quot;) # Display figure inline in Jupyter Notebook. output_notebook() # Display figure. show(p) . ValueError Traceback (most recent call last) /Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb Cell 33&#39; in &lt;cell line: 11&gt;() &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=7&#39;&gt;8&lt;/a&gt; from bokeh.models import Range1d &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=9&#39;&gt;10&lt;/a&gt; # Read data to json. &gt; &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=10&#39;&gt;11&lt;/a&gt; merged_json = json.loads(points_to_map.to_json()) &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=11&#39;&gt;12&lt;/a&gt; # Convert to String like object. &lt;a href=&#39;vscode-notebook-cell:/Users/paskin/Dev/rosreestr_parser/data_analysis_v2_geo.ipynb#ch0000038?line=12&#39;&gt;13&lt;/a&gt; json_data = json.dumps(merged_json) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:750, in GeoDataFrame.to_json(self, na, show_bbox, drop_id, **kwargs) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=695&#39;&gt;696&lt;/a&gt; def to_json(self, na=&#34;null&#34;, show_bbox=False, drop_id=False, **kwargs): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=696&#39;&gt;697&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=697&#39;&gt;698&lt;/a&gt; Returns a GeoJSON representation of the ``GeoDataFrame`` as a string. &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=698&#39;&gt;699&lt;/a&gt; (...) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=746&#39;&gt;747&lt;/a&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=747&#39;&gt;748&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=748&#39;&gt;749&lt;/a&gt; return json.dumps( --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=749&#39;&gt;750&lt;/a&gt; self._to_geo(na=na, show_bbox=show_bbox, drop_id=drop_id), **kwargs &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=750&#39;&gt;751&lt;/a&gt; ) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:897, in GeoDataFrame._to_geo(self, **kwargs) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=888&#39;&gt;889&lt;/a&gt; def _to_geo(self, **kwargs): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=889&#39;&gt;890&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=890&#39;&gt;891&lt;/a&gt; Returns a python feature collection (i.e. the geointerface) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=891&#39;&gt;892&lt;/a&gt; representation of the GeoDataFrame. &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=892&#39;&gt;893&lt;/a&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=893&#39;&gt;894&lt;/a&gt; &#34;&#34;&#34; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=894&#39;&gt;895&lt;/a&gt; geo = { &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=895&#39;&gt;896&lt;/a&gt; &#34;type&#34;: &#34;FeatureCollection&#34;, --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=896&#39;&gt;897&lt;/a&gt; &#34;features&#34;: list(self.iterfeatures(**kwargs)), &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=897&#39;&gt;898&lt;/a&gt; } &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=899&#39;&gt;900&lt;/a&gt; if kwargs.get(&#34;show_bbox&#34;, False): &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=900&#39;&gt;901&lt;/a&gt; geo[&#34;bbox&#34;] = tuple(self.total_bounds) File ~/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py:838, in GeoDataFrame.iterfeatures(self, na, show_bbox, drop_id) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=834&#39;&gt;835&lt;/a&gt; geometries = np.array(self[self._geometry_column_name], copy=False) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=836&#39;&gt;837&lt;/a&gt; if not self.columns.is_unique: --&gt; &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=837&#39;&gt;838&lt;/a&gt; raise ValueError(&#34;GeoDataFrame cannot contain duplicated column names.&#34;) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=839&#39;&gt;840&lt;/a&gt; properties_cols = self.columns.difference([self._geometry_column_name]) &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=841&#39;&gt;842&lt;/a&gt; if len(properties_cols) &gt; 0: &lt;a href=&#39;file:///Users/paskin/Dev/rosreestr_parser/venv_rosreestr/lib/python3.9/site-packages/geopandas/geodataframe.py?line=842&#39;&gt;843&lt;/a&gt; # convert to object to get python scalars. ValueError: GeoDataFrame cannot contain duplicated column names. . points_to_map.loc[points_to_map[&quot;att_region&quot;] == 50] . ID_0 ISO NAME_0 ID_1 NAME_1 HASC_1 CCN_1 CCA_1 TYPE_1 ENGTYPE_1 NL_NAME_1 VARNAME_1 geometry year att_region decisions_total acceptions_total rejections_total rejections_share . 49 188 | RUS | Russia | 50 | Novosibirsk | RU.NS | 0 | 0 | Oblast | Region | Новосибирская область | Novosibirskaya Oblast | POLYGON ((76.25723 57.20467, 76.42656 57.18681... | 2021.0 | 50 | 154293.0 | 41475.0 | 112818.0 | 0.731193 | .",
            "url": "https://evgeniypaskin.github.io/kadeng_stats/2022/05/20/publish_v1.html",
            "relUrl": "/2022/05/20/publish_v1.html",
            "date": " • May 20, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://evgeniypaskin.github.io/kadeng_stats/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://evgeniypaskin.github.io/kadeng_stats/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://evgeniypaskin.github.io/kadeng_stats/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://evgeniypaskin.github.io/kadeng_stats/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}